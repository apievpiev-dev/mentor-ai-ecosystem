#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á
"""

import asyncio
import json
import logging
import time
import uuid
import numpy as np
import torch
import torch.nn as nn
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass, asdict
import random
from pathlib import Path

from ai_engine import generate_ai_response
from neural_network_creator_agent import NetworkArchitecture

logger = logging.getLogger(__name__)

@dataclass
class ArchitectureTemplate:
    """–®–∞–±–ª–æ–Ω –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
    name: str
    description: str
    task_type: str  # classification, regression, generation, vision, nlp
    input_size: int
    output_size: int
    layers: List[Dict[str, Any]]
    activation_functions: List[str]
    optimizer: str
    loss_function: str
    learning_rate: float
    batch_size: int
    epochs: int
    complexity_score: float  # 1-10
    performance_estimate: float  # 0-1

@dataclass
class ArchitectureSearchResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
    best_architecture: NetworkArchitecture
    search_time: float
    iterations: int
    tested_architectures: List[NetworkArchitecture]
    performance_ranking: List[Tuple[NetworkArchitecture, float]]

class NeuralArchitectureGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π"""
    
    def __init__(self):
        self.architecture_templates = {}
        self.performance_database = {}
        self.search_history = []
        self._setup_templates()
        self._setup_directories()
    
    def _setup_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        directories = [
            "/workspace/neural_networks/architectures",
            "/workspace/neural_networks/architecture_templates",
            "/workspace/neural_networks/search_results",
            "/workspace/neural_networks/performance_db"
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
    
    def _setup_templates(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∞–±–ª–æ–Ω–æ–≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä"""
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        self.architecture_templates["simple_classifier"] = ArchitectureTemplate(
            name="Simple Classifier",
            description="–ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏",
            task_type="classification",
            input_size=784,
            output_size=10,
            layers=[
                {"type": "linear", "input_size": 784, "output_size": 128, "activation": "relu"},
                {"type": "linear", "input_size": 128, "output_size": 64, "activation": "relu"},
                {"type": "linear", "input_size": 64, "output_size": 10, "activation": "softmax"}
            ],
            activation_functions=["relu", "relu", "softmax"],
            optimizer="adam",
            loss_function="cross_entropy",
            learning_rate=0.001,
            batch_size=32,
            epochs=20,
            complexity_score=3.0,
            performance_estimate=0.85
        )
        
        # –†–µ–≥—Ä–µ—Å—Å–∏—è
        self.architecture_templates["regression_net"] = ArchitectureTemplate(
            name="Regression Network",
            description="–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏",
            task_type="regression",
            input_size=100,
            output_size=1,
            layers=[
                {"type": "linear", "input_size": 100, "output_size": 64, "activation": "relu"},
                {"type": "linear", "input_size": 64, "output_size": 32, "activation": "relu"},
                {"type": "linear", "input_size": 32, "output_size": 1, "activation": "linear"}
            ],
            activation_functions=["relu", "relu", "linear"],
            optimizer="adam",
            loss_function="mse",
            learning_rate=0.001,
            batch_size=32,
            epochs=50,
            complexity_score=2.5,
            performance_estimate=0.80
        )
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        self.architecture_templates["generator_net"] = ArchitectureTemplate(
            name="Generator Network",
            description="–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö",
            task_type="generation",
            input_size=100,
            output_size=784,
            layers=[
                {"type": "linear", "input_size": 100, "output_size": 256, "activation": "relu"},
                {"type": "linear", "input_size": 256, "output_size": 512, "activation": "relu"},
                {"type": "linear", "input_size": 512, "output_size": 784, "activation": "sigmoid"}
            ],
            activation_functions=["relu", "relu", "sigmoid"],
            optimizer="adam",
            loss_function="bce",
            learning_rate=0.0002,
            batch_size=64,
            epochs=100,
            complexity_score=4.0,
            performance_estimate=0.75
        )
        
        # –ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ
        self.architecture_templates["cnn_classifier"] = ArchitectureTemplate(
            name="CNN Classifier",
            description="–°–≤–µ—Ä—Ç–æ—á–Ω–∞—è —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
            task_type="vision",
            input_size=3072,  # 32x32x3
            output_size=10,
            layers=[
                {"type": "conv2d", "in_channels": 3, "out_channels": 32, "kernel_size": 3, "activation": "relu"},
                {"type": "maxpool2d", "kernel_size": 2},
                {"type": "conv2d", "in_channels": 32, "out_channels": 64, "kernel_size": 3, "activation": "relu"},
                {"type": "maxpool2d", "kernel_size": 2},
                {"type": "linear", "input_size": 64*6*6, "output_size": 128, "activation": "relu"},
                {"type": "linear", "input_size": 128, "output_size": 10, "activation": "softmax"}
            ],
            activation_functions=["relu", "relu", "relu", "softmax"],
            optimizer="adam",
            loss_function="cross_entropy",
            learning_rate=0.001,
            batch_size=32,
            epochs=30,
            complexity_score=6.0,
            performance_estimate=0.90
        )
        
        # NLP
        self.architecture_templates["rnn_classifier"] = ArchitectureTemplate(
            name="RNN Classifier",
            description="–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–∞—è —Å–µ—Ç—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞",
            task_type="nlp",
            input_size=1000,
            output_size=5,
            layers=[
                {"type": "embedding", "vocab_size": 10000, "embedding_dim": 128},
                {"type": "lstm", "input_size": 128, "hidden_size": 64, "num_layers": 2},
                {"type": "linear", "input_size": 64, "output_size": 32, "activation": "relu"},
                {"type": "linear", "input_size": 32, "output_size": 5, "activation": "softmax"}
            ],
            activation_functions=["relu", "softmax"],
            optimizer="adam",
            loss_function="cross_entropy",
            learning_rate=0.001,
            batch_size=16,
            epochs=25,
            complexity_score=7.0,
            performance_estimate=0.88
        )
        
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.architecture_templates)} —à–∞–±–ª–æ–Ω–æ–≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä")
    
    async def generate_architecture(self, task_description: str, 
                                 task_type: str = None,
                                 input_size: int = None,
                                 output_size: int = None,
                                 complexity: str = "medium") -> NetworkArchitecture:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        try:
            logger.info(f"üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è: {task_description}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏
            if not task_type:
                task_type = await self._detect_task_type(task_description)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –≤—Ö–æ–¥–∞ –∏ –≤—ã—Ö–æ–¥–∞
            if not input_size or not output_size:
                input_size, output_size = await self._estimate_io_sizes(task_description, task_type)
            
            # –í—ã–±–∏—Ä–∞–µ–º –±–∞–∑–æ–≤—ã–π —à–∞–±–ª–æ–Ω
            base_template = await self._select_base_template(task_type, complexity)
            
            # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —à–∞–±–ª–æ–Ω –ø–æ–¥ –∑–∞–¥–∞—á—É
            adapted_architecture = await self._adapt_template(base_template, task_description, 
                                                           input_size, output_size, complexity)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            improved_architecture = await self._improve_with_ai(adapted_architecture, task_description)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            await self._save_architecture(improved_architecture)
            
            logger.info(f"‚úÖ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞: {improved_architecture.name}")
            return improved_architecture
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: {e}")
            raise
    
    async def _detect_task_type(self, task_description: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
            ai_prompt = f"""
            –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –∑–∞–¥–∞—á–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø–∏—Å–∞–Ω–∏—è:
            "{task_description}"
            
            –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —Å–ª–æ–≤–æ –∏–∑ —Å–ø–∏—Å–∫–∞:
            - classification (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)
            - regression (—Ä–µ–≥—Ä–µ—Å—Å–∏—è) 
            - generation (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è)
            - vision (–∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ)
            - nlp (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞)
            """
            
            ai_response = await generate_ai_response(ai_prompt)
            task_type = ai_response.strip().lower()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
            valid_types = ["classification", "regression", "generation", "vision", "nlp"]
            if task_type not in valid_types:
                task_type = "classification"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            
            logger.info(f"üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω —Ç–∏–ø –∑–∞–¥–∞—á–∏: {task_type}")
            return task_type
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏: {e}")
            return "classification"
    
    async def _estimate_io_sizes(self, task_description: str, task_type: str) -> Tuple[int, int]:
        """–û—Ü–µ–Ω–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ –≤—Ö–æ–¥–∞ –∏ –≤—ã—Ö–æ–¥–∞"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∞–∑–º–µ—Ä–æ–≤
            ai_prompt = f"""
            –û—Ü–µ–Ω–∏ —Ä–∞–∑–º–µ—Ä—ã –≤—Ö–æ–¥–∞ –∏ –≤—ã—Ö–æ–¥–∞ –¥–ª—è –∑–∞–¥–∞—á–∏:
            "{task_description}"
            –¢–∏–ø –∑–∞–¥–∞—á–∏: {task_type}
            
            –í–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏:
            - input_size: —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—á–∏—Å–ª–æ)
            - output_size: —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—á–∏—Å–ª–æ)
            
            –ü—Ä–∏–º–µ—Ä—ã:
            - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π 28x28: input_size=784, output_size=10
            - –†–µ–≥—Ä–µ—Å—Å–∏—è —Å 50 –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏: input_size=50, output_size=1
            - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞: input_size=100, output_size=1000
            """
            
            ai_response = await generate_ai_response(ai_prompt)
            
            try:
                sizes = json.loads(ai_response)
                input_size = sizes.get("input_size", 784)
                output_size = sizes.get("output_size", 10)
            except json.JSONDecodeError:
                # Fallback –∑–Ω–∞—á–µ–Ω–∏—è
                if task_type == "classification":
                    input_size, output_size = 784, 10
                elif task_type == "regression":
                    input_size, output_size = 100, 1
                elif task_type == "generation":
                    input_size, output_size = 100, 784
                elif task_type == "vision":
                    input_size, output_size = 3072, 10
                elif task_type == "nlp":
                    input_size, output_size = 1000, 5
                else:
                    input_size, output_size = 784, 10
            
            logger.info(f"üìè –û—Ü–µ–Ω–µ–Ω—ã —Ä–∞–∑–º–µ—Ä—ã: –≤—Ö–æ–¥={input_size}, –≤—ã—Ö–æ–¥={output_size}")
            return input_size, output_size
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–∞–∑–º–µ—Ä–æ–≤: {e}")
            return 784, 10
    
    async def _select_base_template(self, task_type: str, complexity: str) -> ArchitectureTemplate:
        """–í—ã–±–æ—Ä –±–∞–∑–æ–≤–æ–≥–æ —à–∞–±–ª–æ–Ω–∞"""
        try:
            # –§–∏–ª—å—Ç—Ä—É–µ–º —à–∞–±–ª–æ–Ω—ã –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏
            suitable_templates = [
                template for template in self.architecture_templates.values()
                if template.task_type == task_type
            ]
            
            if not suitable_templates:
                # –ï—Å–ª–∏ –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —à–∞–±–ª–æ–Ω–æ–≤, –±–µ—Ä–µ–º –ø—Ä–æ—Å—Ç–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
                suitable_templates = [self.architecture_templates["simple_classifier"]]
            
            # –í—ã–±–∏—Ä–∞–µ–º –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            if complexity == "simple":
                selected = min(suitable_templates, key=lambda t: t.complexity_score)
            elif complexity == "complex":
                selected = max(suitable_templates, key=lambda t: t.complexity_score)
            else:  # medium
                selected = suitable_templates[len(suitable_templates) // 2]
            
            logger.info(f"üìã –í—ã–±—Ä–∞–Ω —à–∞–±–ª–æ–Ω: {selected.name}")
            return selected
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ —à–∞–±–ª–æ–Ω–∞: {e}")
            return self.architecture_templates["simple_classifier"]
    
    async def _adapt_template(self, template: ArchitectureTemplate, task_description: str,
                            input_size: int, output_size: int, complexity: str) -> NetworkArchitecture:
        """–ê–¥–∞–ø—Ç–∞—Ü–∏—è —à–∞–±–ª–æ–Ω–∞ –ø–æ–¥ –∑–∞–¥–∞—á—É"""
        try:
            # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã —Å–ª–æ–µ–≤
            adapted_layers = []
            prev_size = input_size
            
            for i, layer in enumerate(template.layers):
                if layer["type"] == "linear":
                    # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã
                    if i == len(template.layers) - 1:  # –ü–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π
                        layer_size = output_size
                    else:
                        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º —Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏
                        original_size = layer["output_size"]
                        scale_factor = input_size / template.input_size
                        layer_size = max(int(original_size * scale_factor), 32)
                    
                    adapted_layers.append({
                        "type": "linear",
                        "input_size": prev_size,
                        "output_size": layer_size,
                        "activation": layer["activation"]
                    })
                    prev_size = layer_size
                else:
                    # –ö–æ–ø–∏—Ä—É–µ–º –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã —Å–ª–æ–µ–≤ –∫–∞–∫ –µ—Å—Ç—å
                    adapted_layers.append(layer.copy())
            
            # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            learning_rate = template.learning_rate
            batch_size = template.batch_size
            epochs = template.epochs
            
            if complexity == "simple":
                learning_rate *= 1.5
                batch_size = min(batch_size * 2, 128)
                epochs = max(epochs // 2, 10)
            elif complexity == "complex":
                learning_rate *= 0.5
                batch_size = max(batch_size // 2, 16)
                epochs = min(epochs * 2, 200)
            
            # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
            architecture = NetworkArchitecture(
                name=f"generated_{uuid.uuid4().hex[:8]}",
                layers=adapted_layers,
                input_size=input_size,
                output_size=output_size,
                activation_functions=template.activation_functions,
                optimizer=template.optimizer,
                loss_function=template.loss_function,
                learning_rate=learning_rate,
                batch_size=batch_size,
                epochs=epochs,
                created_at=datetime.now().isoformat()
            )
            
            logger.info(f"üîß –®–∞–±–ª–æ–Ω –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ–¥ –∑–∞–¥–∞—á—É")
            return architecture
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ —à–∞–±–ª–æ–Ω–∞: {e}")
            raise
    
    async def _improve_with_ai(self, architecture: NetworkArchitecture, 
                             task_description: str) -> NetworkArchitecture:
        """–£–ª—É—á—à–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –ø–æ–º–æ—â—å—é AI"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            ai_prompt = f"""
            –£–ª—É—á—à–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–ª—è –∑–∞–¥–∞—á–∏: {task_description}
            
            –¢–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
            {json.dumps(asdict(architecture), indent=2)}
            
            –ü—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è –∏ –≤–µ—Ä–Ω–∏ –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            - name: –Ω–∞–∑–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            - layers: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–µ–≤
            - input_size: —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞
            - output_size: —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞
            - activation_functions: —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
            - optimizer: –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
            - loss_function: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
            - learning_rate: —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
            - batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            - epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            - created_at: –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è
            
            –£—á—Ç–∏:
            - –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            - –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
            - –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
            - –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é
            """
            
            ai_response = await generate_ai_response(ai_prompt)
            
            try:
                # –ü–∞—Ä—Å–∏–º —É–ª—É—á—à–µ–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
                improved_data = json.loads(ai_response)
                improved_architecture = NetworkArchitecture(**improved_data)
                
                logger.info("ü§ñ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —É–ª—É—á—à–µ–Ω–∞ —Å –ø–æ–º–æ—â—å—é AI")
                return improved_architecture
                
            except (json.JSONDecodeError, TypeError) as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ä—Å–∏—Ç—å AI —É–ª—É—á—à–µ–Ω–∏—è: {e}")
                return architecture
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è —Å AI: {e}")
            return architecture
    
    async def search_optimal_architecture(self, task_description: str, 
                                        search_iterations: int = 10) -> ArchitectureSearchResult:
        """–ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
        try:
            logger.info(f"üîç –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (–∏—Ç–µ—Ä–∞—Ü–∏–π: {search_iterations})")
            
            start_time = time.time()
            tested_architectures = []
            performance_scores = []
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            for i in range(search_iterations):
                try:
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
                    complexity = random.choice(["simple", "medium", "complex"])
                    architecture = await self.generate_architecture(
                        task_description, complexity=complexity
                    )
                    
                    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å–∏–º—É–ª—è—Ü–∏—è)
                    performance = await self._simulate_performance(architecture, task_description)
                    
                    tested_architectures.append(architecture)
                    performance_scores.append(performance)
                    
                    logger.info(f"üìä –ò—Ç–µ—Ä–∞—Ü–∏—è {i+1}/{search_iterations}: –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å {performance:.3f}")
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i+1}: {e}")
                    continue
            
            # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
            if tested_architectures:
                best_idx = np.argmax(performance_scores)
                best_architecture = tested_architectures[best_idx]
                best_performance = performance_scores[best_idx]
                
                # –°–æ–∑–¥–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥
                performance_ranking = list(zip(tested_architectures, performance_scores))
                performance_ranking.sort(key=lambda x: x[1], reverse=True)
                
                search_time = time.time() - start_time
                
                result = ArchitectureSearchResult(
                    best_architecture=best_architecture,
                    search_time=search_time,
                    iterations=len(tested_architectures),
                    tested_architectures=tested_architectures,
                    performance_ranking=performance_ranking
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                await self._save_search_result(result)
                
                logger.info(f"üèÜ –ù–∞–π–¥–µ–Ω–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å {best_performance:.3f}")
                return result
            else:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: {e}")
            raise
    
    async def _simulate_performance(self, architecture: NetworkArchitecture, 
                                  task_description: str) -> float:
        """–°–∏–º—É–ª—è—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            base_score = 0.5
            
            # –û—Ü–µ–Ω–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–ª–æ–µ–≤
            layer_count = len(architecture.layers)
            if 2 <= layer_count <= 5:
                base_score += 0.1
            elif layer_count > 5:
                base_score += 0.05
            
            # –û—Ü–µ–Ω–∫–∞ –ø–æ —Ä–∞–∑–º–µ—Ä—É —Å–ª–æ–µ–≤
            total_neurons = sum(layer.get("output_size", 0) for layer in architecture.layers)
            if 100 <= total_neurons <= 1000:
                base_score += 0.1
            elif total_neurons > 1000:
                base_score += 0.05
            
            # –û—Ü–µ–Ω–∫–∞ –ø–æ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
            if 0.0001 <= architecture.learning_rate <= 0.01:
                base_score += 0.1
            
            if 16 <= architecture.batch_size <= 128:
                base_score += 0.1
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            random_factor = random.uniform(-0.1, 0.1)
            final_score = min(max(base_score + random_factor, 0.0), 1.0)
            
            return final_score
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–º—É–ª—è—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
            return 0.5
    
    async def _save_architecture(self, architecture: NetworkArchitecture):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
        try:
            arch_path = f"/workspace/neural_networks/architectures/{architecture.name}_architecture.json"
            with open(arch_path, 'w', encoding='utf-8') as f:
                json.dump(asdict(architecture), f, indent=2, ensure_ascii=False)
            
            logger.info(f"üíæ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {arch_path}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: {e}")
    
    async def _save_search_result(self, result: ArchitectureSearchResult):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–æ–∏—Å–∫–∞"""
        try:
            result_data = {
                "best_architecture": asdict(result.best_architecture),
                "search_time": result.search_time,
                "iterations": result.iterations,
                "tested_architectures": [asdict(arch) for arch in result.tested_architectures],
                "performance_ranking": [
                    {"architecture": asdict(arch), "performance": perf}
                    for arch, perf in result.performance_ranking
                ],
                "timestamp": datetime.now().isoformat()
            }
            
            result_path = f"/workspace/neural_networks/search_results/search_{int(time.time())}.json"
            with open(result_path, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {result_path}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–æ–∏—Å–∫–∞: {e}")
    
    async def get_available_templates(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤"""
        try:
            templates_info = []
            
            for name, template in self.architecture_templates.items():
                templates_info.append({
                    "name": template.name,
                    "description": template.description,
                    "task_type": template.task_type,
                    "complexity_score": template.complexity_score,
                    "performance_estimate": template.performance_estimate
                })
            
            return {
                "templates": templates_info,
                "total_templates": len(templates_info)
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —à–∞–±–ª–æ–Ω–æ–≤: {e}")
            return {"error": str(e)}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä
architecture_generator = NeuralArchitectureGenerator()

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    try:
        logger.info("üß† –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –∑–∞–ø—É—â–µ–Ω")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
        logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä...")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        architecture = await architecture_generator.generate_architecture(
            "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —Ü–∏—Ñ—Ä MNIST",
            complexity="medium"
        )
        
        logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {architecture.name}")
        logger.info(f"üìä –°–ª–æ–µ–≤: {len(architecture.layers)}")
        logger.info(f"üéØ –í—Ö–æ–¥: {architecture.input_size}, –í—ã—Ö–æ–¥: {architecture.output_size}")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        logger.info("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã...")
        
        search_result = await architecture_generator.search_optimal_architecture(
            "–†–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω –Ω–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å",
            search_iterations=5
        )
        
        logger.info(f"üèÜ –ù–∞–π–¥–µ–Ω–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {search_result.best_architecture.name}")
        logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {search_result.search_time:.2f} —Å–µ–∫")
        logger.info(f"üîÑ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä: {search_result.iterations}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–º —Ü–∏–∫–ª–µ
        while True:
            await asyncio.sleep(1)
            
    except KeyboardInterrupt:
        logger.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä...")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    asyncio.run(main())