# üÜì AI Manager - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤

## üéØ –û–±–∑–æ—Ä

AI Manager —Ç–µ–ø–µ—Ä—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç **–±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã**! –ë–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω—ã –ø–ª–∞—Ç–Ω—ã–µ API –∫–ª—é—á–∏ OpenAI - —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –∏ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏.

## üîå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã

### 1. ü§ñ Ollama (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
**–õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞—à–µ–º —Å–µ—Ä–≤–µ—Ä–µ**

- ‚úÖ **–ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ—Å–ø–ª–∞—Ç–Ω–æ**
- ‚úÖ **–ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö**
- ‚úÖ **–ë—ã—Å—Ç—Ä–∞—è —Ä–∞–±–æ—Ç–∞**
- ‚úÖ **–ú–Ω–æ–≥–æ –º–æ–¥–µ–ª–µ–π**

**–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏:**
- `llama2:7b` - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
- `codellama:7b` - –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞
- `mistral:7b` - –±—ã—Å—Ç—Ä–∞—è –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è
- `orca-mini:3b` - –ª–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å

### 2. üåê Hugging Face (API)
**–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ API**

- ‚úÖ **–ë–µ—Å–ø–ª–∞—Ç–Ω–æ** (—Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏)
- ‚úÖ **–ú–Ω–æ–≥–æ –º–æ–¥–µ–ª–µ–π**
- ‚úÖ **–ü—Ä–æ—Å—Ç–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞**

**–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏:**
- `microsoft/DialoGPT-medium`
- `gpt2-medium`
- `distilgpt2`

### 3. üè† Local Provider
**–ü—Ä–æ—Å—Ç–∞—è –∏–º–∏—Ç–∞—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏**

- ‚úÖ **–í—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç**
- ‚úÖ **–ù–µ —Ç—Ä–µ–±—É–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞**
- ‚úÖ **–ë—ã—Å—Ç—Ä—ã–π –æ—Ç–∫–ª–∏–∫**

## üöÄ –ë—ã—Å—Ç—Ä–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

### –í–∞—Ä–∏–∞–Ω—Ç 1: Docker (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
# –ö–ª–æ–Ω–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç
git clone <repository>
cd ai_manager

# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π
./deploy.sh
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –õ–æ–∫–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
# 1. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 2. –ó–∞–ø—É—Å–∫–∞–µ–º Ollama
ollama serve

# 3. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
ollama pull llama2:7b

# 4. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt

# 5. –ó–∞–ø—É—Å–∫–∞–µ–º AI Manager
python start_server.py
```

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –§–∞–π–ª .env

```env
# Ollama –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama2:7b

# Hugging Face (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
HUGGINGFACE_TOKEN=your_token_here
HUGGINGFACE_MODEL=microsoft/DialoGPT-medium

# OpenAI (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –µ—Å—Ç—å)
OPENAI_API_KEY=your_key_here
```

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤

–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä:

1. **Ollama** (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
2. **Hugging Face** (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω)
3. **Local Provider** (fallback)

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤

```bash
python demo_free.py
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤

```bash
curl http://localhost:8000/api/stats
```

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤

| –ü—Ä–æ–≤–∞–π–¥–µ—Ä | –°–∫–æ—Ä–æ—Å—Ç—å | –ö–∞—á–µ—Å—Ç–≤–æ | –ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å | –°—Ç–æ–∏–º–æ—Å—Ç—å |
|-----------|----------|----------|-------------|-----------|
| Ollama | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | üÜì |
| Hugging Face | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | üÜì |
| OpenAI | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê | üí∞ |
| Local | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | üÜì |

## üõ†Ô∏è –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### Ollama –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è

```bash
# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
ollama list

# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º
sudo systemctl restart ollama

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏
journalctl -u ollama -f
```

### Hugging Face API –æ—à–∏–±–∫–∏

```bash
# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–∫–µ–Ω
curl -H "Authorization: Bearer YOUR_TOKEN" https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium
```

### –ù–∏–∑–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

```bash
# –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å Ollama
ollama pull orca-mini:3b

# –ò–ª–∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤ .env
OLLAMA_MODEL=orca-mini:3b
```

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `orca-mini:3b` - –±—ã—Å—Ç—Ä–∞—è –∏ –ª–µ–≥–∫–∞—è
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ Local Provider –∫–∞–∫ fallback

### –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `llama2:7b` –∏–ª–∏ `mistral:7b`
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ Redis –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ PostgreSQL –≤–º–µ—Å—Ç–æ SQLite

### –î–ª—è –≤—ã—Å–æ–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ Ollama
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤—â–∏–∫ –Ω–∞–≥—Ä—É–∑–∫–∏
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

## üîß –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è Ollama

```bash
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ ~/.ollama/config.json
{
  "gpu_layers": 35,
  "num_ctx": 2048,
  "num_thread": 8
}
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤

```bash
# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU
nvidia-smi

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å
free -h

# –ü—Ä–æ–≤–µ—Ä—è–µ–º CPU
htop
```

## üéâ –ì–æ—Ç–æ–≤–æ!

–¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ AI –∞–≥–µ–Ω—Ç–æ–≤:

- üÜì **–ë–µ–∑ –ø–ª–∞—Ç–Ω—ã—Ö API**
- üöÄ **–ë—ã—Å—Ç—Ä–∞—è —Ä–∞–±–æ—Ç–∞**
- üîí **–ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö**
- üìà **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**

**–ó–∞–ø—É—Å–∫–∞–π—Ç–µ –∏ –Ω–∞—Å–ª–∞–∂–¥–∞–π—Ç–µ—Å—å!**

```bash
./deploy.sh
# –û—Ç–∫—Ä–æ–π—Ç–µ http://localhost:8000
```


