#!/usr/bin/env python3
"""
–ê–≥–µ–Ω—Ç Neural Network Creator
–°–æ–∑–¥–∞–µ—Ç, –æ–±—É—á–∞–µ—Ç –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
"""

import asyncio
import json
import logging
import subprocess
import time
import uuid
import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, asdict
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

from multi_agent_system import BaseAgent, AgentType
from ai_engine import ai_engine, generate_ai_response

logger = logging.getLogger(__name__)

@dataclass
class NetworkArchitecture:
    """–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
    name: str
    layers: List[Dict[str, Any]]
    input_size: int
    output_size: int
    activation_functions: List[str]
    optimizer: str
    loss_function: str
    learning_rate: float
    batch_size: int
    epochs: int
    created_at: str
    performance_metrics: Dict[str, float] = None

@dataclass
class TrainingData:
    """–î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    name: str
    data_type: str  # classification, regression, generation
    input_shape: Tuple[int, ...]
    output_shape: Tuple[int, ...]
    samples_count: int
    features: List[str]
    target_column: str
    data_path: str

class NeuralNetworkCreatorAgent(BaseAgent):
    """–ê–≥–µ–Ω—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π"""
    
    def __init__(self, agent_id: str = None):
        super().__init__(
            agent_id or str(uuid.uuid4()),
            AgentType.SYSTEM_ADMIN,
            "Neural Network Creator",
            "–°–æ–∑–¥–∞–µ—Ç, –æ–±—É—á–∞–µ—Ç –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"
        )
        self.created_networks = {}
        self.training_data = {}
        self.performance_history = []
        self._setup_skills()
        self._setup_directories()
    
    def _setup_skills(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞–≤—ã–∫–æ–≤ –∞–≥–µ–Ω—Ç–∞"""
        self.add_skill("create_network", self._handle_create_network)
        self.add_skill("train_network", self._handle_train_network)
        self.add_skill("optimize_network", self._handle_optimize_network)
        self.add_skill("generate_architecture", self._handle_generate_architecture)
        self.add_skill("evaluate_network", self._handle_evaluate_network)
        self.add_skill("deploy_network", self._handle_deploy_network)
        self.add_skill("list_networks", self._handle_list_networks)
        self.add_skill("create_training_data", self._handle_create_training_data)
        self.add_skill("visualize_network", self._handle_visualize_network)
        self.add_skill("auto_create_network", self._handle_auto_create_network)
    
    def _setup_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        directories = [
            "/workspace/neural_networks",
            "/workspace/neural_networks/models",
            "/workspace/neural_networks/data",
            "/workspace/neural_networks/visualizations",
            "/workspace/neural_networks/deployments",
            "/workspace/neural_networks/logs"
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
    
    async def _handle_create_network(self, content: Dict[str, Any]) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        try:
            network_name = content.get("name", f"network_{uuid.uuid4().hex[:8]}")
            network_type = content.get("type", "classification")
            input_size = content.get("input_size", 784)
            output_size = content.get("output_size", 10)
            hidden_layers = content.get("hidden_layers", [128, 64])
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
            architecture = await self._generate_network_architecture(
                network_name, network_type, input_size, output_size, hidden_layers
            )
            
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å PyTorch
            model = self._create_pytorch_model(architecture)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
            self.created_networks[network_name] = {
                "architecture": architecture,
                "model": model,
                "status": "created",
                "created_at": datetime.now().isoformat(),
                "training_history": []
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            await self._save_network(network_name)
            
            return {
                "message": f"–ù–µ–π—Ä–æ—Å–µ—Ç—å '{network_name}' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞",
                "network_name": network_name,
                "architecture": asdict(architecture),
                "status": "created"
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: {e}")
            return {"error": str(e)}
    
    async def _handle_auto_create_network(self, content: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —Å AI"""
        try:
            task_description = content.get("task", "")
            if not task_description:
                return {"error": "–ù–µ —É–∫–∞–∑–∞–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏"}
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            ai_prompt = f"""
            –°–æ–∑–¥–∞–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–ª—è –∑–∞–¥–∞—á–∏: {task_description}
            
            –í–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏:
            - name: –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–µ—Ç–∏
            - type: —Ç–∏–ø –∑–∞–¥–∞—á–∏ (classification/regression/generation)
            - input_size: —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞
            - output_size: —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞
            - hidden_layers: —Å–ø–∏—Å–æ–∫ —Ä–∞–∑–º–µ—Ä–æ–≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤
            - activation_functions: —Å–ø–∏—Å–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
            - optimizer: –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
            - loss_function: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
            - learning_rate: —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
            - batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            - epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            """
            
            ai_response = await generate_ai_response(ai_prompt)
            
            try:
                # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç –æ—Ç AI
                network_config = json.loads(ai_response)
            except json.JSONDecodeError:
                # –ï—Å–ª–∏ AI –Ω–µ –≤–µ—Ä–Ω—É–ª –≤–∞–ª–∏–¥–Ω—ã–π JSON, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
                network_config = {
                    "name": f"auto_network_{uuid.uuid4().hex[:8]}",
                    "type": "classification",
                    "input_size": 784,
                    "output_size": 10,
                    "hidden_layers": [128, 64],
                    "activation_functions": ["relu", "relu"],
                    "optimizer": "adam",
                    "loss_function": "cross_entropy",
                    "learning_rate": 0.001,
                    "batch_size": 32,
                    "epochs": 10
                }
            
            # –°–æ–∑–¥–∞–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç—å
            result = await self._handle_create_network(network_config)
            
            return {
                "message": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ",
                "ai_suggestion": ai_response,
                "created_network": result
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è: {e}")
            return {"error": str(e)}
    
    async def _generate_network_architecture(self, name: str, network_type: str, 
                                           input_size: int, output_size: int, 
                                           hidden_layers: List[int]) -> NetworkArchitecture:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        activation_functions = ["relu"] * len(hidden_layers)
        if network_type == "classification":
            activation_functions.append("softmax")
        elif network_type == "regression":
            activation_functions.append("linear")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å
        if network_type == "classification":
            loss_function = "cross_entropy"
        elif network_type == "regression":
            loss_function = "mse"
        else:
            loss_function = "mse"
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–∏
        layers = []
        prev_size = input_size
        
        for i, layer_size in enumerate(hidden_layers):
            layers.append({
                "type": "linear",
                "input_size": prev_size,
                "output_size": layer_size,
                "activation": activation_functions[i]
            })
            prev_size = layer_size
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        layers.append({
            "type": "linear",
            "input_size": prev_size,
            "output_size": output_size,
            "activation": activation_functions[-1]
        })
        
        return NetworkArchitecture(
            name=name,
            layers=layers,
            input_size=input_size,
            output_size=output_size,
            activation_functions=activation_functions,
            optimizer="adam",
            loss_function=loss_function,
            learning_rate=0.001,
            batch_size=32,
            epochs=10,
            created_at=datetime.now().isoformat()
        )
    
    def _create_pytorch_model(self, architecture: NetworkArchitecture) -> nn.Module:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ PyTorch"""
        
        class CustomNetwork(nn.Module):
            def __init__(self, arch: NetworkArchitecture):
                super(CustomNetwork, self).__init__()
                self.layers = nn.ModuleList()
                
                for layer_config in arch.layers:
                    if layer_config["type"] == "linear":
                        self.layers.append(
                            nn.Linear(layer_config["input_size"], layer_config["output_size"])
                        )
                
                self.activation_functions = arch.activation_functions
            
            def forward(self, x):
                for i, layer in enumerate(self.layers):
                    x = layer(x)
                    if i < len(self.activation_functions) - 1:  # –ù–µ –ø—Ä–∏–º–µ–Ω—è–µ–º –∞–∫—Ç–∏–≤–∞—Ü–∏—é –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Å–ª–æ—é
                        if self.activation_functions[i] == "relu":
                            x = torch.relu(x)
                        elif self.activation_functions[i] == "sigmoid":
                            x = torch.sigmoid(x)
                        elif self.activation_functions[i] == "tanh":
                            x = torch.tanh(x)
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –∞–∫—Ç–∏–≤–∞—Ü–∏—é
                if self.activation_functions[-1] == "softmax":
                    x = torch.softmax(x, dim=1)
                elif self.activation_functions[-1] == "sigmoid":
                    x = torch.sigmoid(x)
                
                return x
        
        return CustomNetwork(architecture)
    
    async def _handle_train_network(self, content: Dict[str, Any]) -> Dict[str, Any]:
        """–û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        try:
            network_name = content.get("network_name", "")
            if network_name not in self.created_networks:
                return {"error": f"–ù–µ–π—Ä–æ—Å–µ—Ç—å '{network_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            data_name = content.get("data_name", "default")
            if data_name not in self.training_data:
                # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                await self._create_test_data(data_name)
            
            training_data = self.training_data[data_name]
            network_info = self.created_networks[network_name]
            model = network_info["model"]
            architecture = network_info["architecture"]
            
            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            X_train, y_train, X_test, y_test = self._generate_test_data(
                training_data.input_shape, training_data.output_shape, training_data.samples_count
            )
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
            criterion = self._get_loss_function(architecture.loss_function)
            optimizer = self._get_optimizer(model, architecture.optimizer, architecture.learning_rate)
            
            # –û–±—É—á–µ–Ω–∏–µ
            training_history = []
            model.train()
            
            for epoch in range(architecture.epochs):
                epoch_loss = 0.0
                correct = 0
                total = 0
                
                # –ë–∞—Ç—á–∏
                for i in range(0, len(X_train), architecture.batch_size):
                    batch_X = X_train[i:i+architecture.batch_size]
                    batch_y = y_train[i:i+architecture.batch_size]
                    
                    optimizer.zero_grad()
                    outputs = model(batch_X)
                    loss = criterion(outputs, batch_y)
                    loss.backward()
                    optimizer.step()
                    
                    epoch_loss += loss.item()
                    _, predicted = torch.max(outputs.data, 1)
                    total += batch_y.size(0)
                    correct += (predicted == batch_y).sum().item()
                
                accuracy = 100 * correct / total
                avg_loss = epoch_loss / (len(X_train) // architecture.batch_size)
                
                training_history.append({
                    "epoch": epoch + 1,
                    "loss": avg_loss,
                    "accuracy": accuracy
                })
                
                logger.info(f"Epoch {epoch+1}/{architecture.epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%")
            
            # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            model.eval()
            with torch.no_grad():
                test_outputs = model(X_test)
                test_loss = criterion(test_outputs, y_test).item()
                _, predicted = torch.max(test_outputs.data, 1)
                test_accuracy = 100 * (predicted == y_test).sum().item() / y_test.size(0)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ—Ç–∏
            network_info["training_history"] = training_history
            network_info["status"] = "trained"
            network_info["test_accuracy"] = test_accuracy
            network_info["test_loss"] = test_loss
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            await self._save_trained_model(network_name, model)
            
            return {
                "message": f"–û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ '{network_name}' –∑–∞–≤–µ—Ä—à–µ–Ω–æ",
                "final_accuracy": test_accuracy,
                "final_loss": test_loss,
                "training_history": training_history
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: {e}")
            return {"error": str(e)}
    
    def _generate_test_data(self, input_shape: Tuple[int, ...], output_shape: Tuple[int, ...], 
                           samples_count: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        X = torch.randn(samples_count, input_shape[0])
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –º–µ—Ç–∫–∏
        if len(output_shape) == 1:
            y = torch.randint(0, output_shape[0], (samples_count,))
        else:
            y = torch.randn(samples_count, output_shape[0])
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
        split_idx = int(0.8 * samples_count)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        return X_train, y_train, X_test, y_test
    
    def _get_loss_function(self, loss_name: str):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å"""
        if loss_name == "cross_entropy":
            return nn.CrossEntropyLoss()
        elif loss_name == "mse":
            return nn.MSELoss()
        elif loss_name == "bce":
            return nn.BCELoss()
        else:
            return nn.CrossEntropyLoss()
    
    def _get_optimizer(self, model: nn.Module, optimizer_name: str, learning_rate: float):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞"""
        if optimizer_name == "adam":
            return optim.Adam(model.parameters(), lr=learning_rate)
        elif optimizer_name == "sgd":
            return optim.SGD(model.parameters(), lr=learning_rate)
        elif optimizer_name == "rmsprop":
            return optim.RMSprop(model.parameters(), lr=learning_rate)
        else:
            return optim.Adam(model.parameters(), lr=learning_rate)
    
    async def _handle_visualize_network(self, content: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        try:
            network_name = content.get("network_name", "")
            if network_name not in self.created_networks:
                return {"error": f"–ù–µ–π—Ä–æ—Å–µ—Ç—å '{network_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
            
            network_info = self.created_networks[network_name]
            architecture = network_info["architecture"]
            
            # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # –ì—Ä–∞—Ñ–∏–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            layer_sizes = [architecture.input_size]
            for layer in architecture.layers:
                layer_sizes.append(layer["output_size"])
            
            ax1.bar(range(len(layer_sizes)), layer_sizes, color='skyblue', alpha=0.7)
            ax1.set_xlabel('–°–ª–æ–∏')
            ax1.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤')
            ax1.set_title(f'–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏: {network_name}')
            ax1.set_xticks(range(len(layer_sizes)))
            ax1.set_xticklabels(['–í—Ö–æ–¥'] + [f'–°–ª–æ–π {i+1}' for i in range(len(layer_sizes)-2)] + ['–í—ã—Ö–æ–¥'])
            
            # –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è
            if network_info["training_history"]:
                history = network_info["training_history"]
                epochs = [h["epoch"] for h in history]
                losses = [h["loss"] for h in history]
                accuracies = [h["accuracy"] for h in history]
                
                ax2_twin = ax2.twinx()
                line1 = ax2.plot(epochs, losses, 'b-', label='–ü–æ—Ç–µ—Ä–∏', linewidth=2)
                line2 = ax2_twin.plot(epochs, accuracies, 'r-', label='–¢–æ—á–Ω–æ—Å—Ç—å', linewidth=2)
                
                ax2.set_xlabel('–≠–ø–æ—Ö–∞')
                ax2.set_ylabel('–ü–æ—Ç–µ—Ä–∏', color='b')
                ax2_twin.set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å (%)', color='r')
                ax2.set_title('–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è')
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ª–µ–≥–µ–Ω–¥—ã
                lines = line1 + line2
                labels = [l.get_label() for l in lines]
                ax2.legend(lines, labels, loc='center right')
            
            plt.tight_layout()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
            viz_path = f"/workspace/neural_networks/visualizations/{network_name}_visualization.png"
            plt.savefig(viz_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            return {
                "message": f"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ç–∏ '{network_name}' —Å–æ–∑–¥–∞–Ω–∞",
                "visualization_path": viz_path,
                "architecture": asdict(architecture)
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            return {"error": str(e)}
    
    async def _handle_list_networks(self, content: Dict[str, Any]) -> Dict[str, Any]:
        """–°–ø–∏—Å–æ–∫ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π"""
        try:
            networks_info = []
            
            for name, info in self.created_networks.items():
                networks_info.append({
                    "name": name,
                    "status": info["status"],
                    "created_at": info["created_at"],
                    "architecture": asdict(info["architecture"]),
                    "test_accuracy": info.get("test_accuracy", 0),
                    "test_loss": info.get("test_loss", 0)
                })
            
            return {
                "networks": networks_info,
                "total_networks": len(networks_info)
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Å–µ—Ç–µ–π: {e}")
            return {"error": str(e)}
    
    async def _save_network(self, network_name: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        try:
            network_info = self.created_networks[network_name]
            architecture = network_info["architecture"]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
            arch_path = f"/workspace/neural_networks/models/{network_name}_architecture.json"
            with open(arch_path, 'w', encoding='utf-8') as f:
                json.dump(asdict(architecture), f, indent=2, ensure_ascii=False)
            
            logger.info(f"‚úÖ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏ '{network_name}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–µ—Ç–∏: {e}")
    
    async def _save_trained_model(self, network_name: str, model: nn.Module):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            model_path = f"/workspace/neural_networks/models/{network_name}_model.pth"
            torch.save(model.state_dict(), model_path)
            logger.info(f"‚úÖ –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å '{network_name}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
    
    async def _create_test_data(self, data_name: str):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        training_data = TrainingData(
            name=data_name,
            data_type="classification",
            input_shape=(784,),
            output_shape=(10,),
            samples_count=1000,
            features=[f"feature_{i}" for i in range(784)],
            target_column="target",
            data_path=f"/workspace/neural_networks/data/{data_name}.csv"
        )
        
        self.training_data[data_name] = training_data

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–≥–µ–Ω—Ç–∞
neural_network_creator = NeuralNetworkCreatorAgent()

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
    async def test_neural_network_creator():
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Neural Network Creator...")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ç–∏
        result = await neural_network_creator._handle_create_network({
            "name": "test_network",
            "type": "classification",
            "input_size": 784,
            "output_size": 10,
            "hidden_layers": [128, 64]
        })
        print(f"–°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ç–∏: {result}")
        
        # –û–±—É—á–µ–Ω–∏–µ —Å–µ—Ç–∏
        result = await neural_network_creator._handle_train_network({
            "network_name": "test_network"
        })
        print(f"–û–±—É—á–µ–Ω–∏–µ —Å–µ—Ç–∏: {result}")
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        result = await neural_network_creator._handle_visualize_network({
            "network_name": "test_network"
        })
        print(f"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: {result}")
    
    asyncio.run(test_neural_network_creator())