#!/usr/bin/env python3
"""
JARVIS Replicator Module
–°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –∏ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
"""

import os
import sys
import json
import time
import asyncio
import subprocess
import logging
import docker
import paramiko
import yaml
import requests
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import threading
import queue

logger = logging.getLogger(__name__)

@dataclass
class ServerInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–µ—Ä–≤–µ—Ä–µ"""
    host: str
    port: int = 22
    username: str = "root"
    ssh_key_path: str = ""
    cpu_cores: int = 0
    memory_gb: int = 0
    disk_gb: int = 0
    status: str = "unknown"  # available, busy, offline
    last_check: Optional[str] = None

@dataclass
class ReplicationTarget:
    """–¶–µ–ª—å –¥–ª—è —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏"""
    server: ServerInfo
    priority: int = 5  # 1-10
    resources_needed: Dict[str, float] = None
    deployment_time: Optional[str] = None
    
    def __post_init__(self):
        if self.resources_needed is None:
            self.resources_needed = {"cpu": 2, "memory": 4, "disk": 20}

class JarvisReplicator:
    """–°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ JARVIS"""
    
    def __init__(self, core):
        self.core = core
        self.docker_client = docker.from_env()
        self.known_servers = []
        self.replication_queue = queue.Queue()
        self.active_deployments = {}
        self.replication_history = []
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.load_config()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ —Å–µ—Ä–≤–µ—Ä–æ–≤
        self.init_server_discovery()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
        self.start_background_processes()
        
    def load_config(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏"""
        config_path = "/home/mentor/jarvis_data/replication_config.yaml"
        
        default_config = {
            "replication": {
                "enabled": True,
                "max_instances": 10,
                "resource_thresholds": {
                    "cpu_percent": 80,
                    "memory_percent": 85,
                    "active_tasks": 10
                },
                "deployment": {
                    "docker_registry": "localhost:5000",
                    "image_tag": "jarvis:latest",
                    "container_name_prefix": "jarvis_node",
                    "port_range": [8080, 8090]
                },
                "server_discovery": {
                    "enabled": True,
                    "scan_networks": ["192.168.1.0/24", "10.0.0.0/24"],
                    "common_ports": [22, 2222],
                    "ssh_timeout": 10
                }
            },
            "monitoring": {
                "health_check_interval": 300,  # 5 –º–∏–Ω—É—Ç
                "performance_check_interval": 60,  # 1 –º–∏–Ω—É—Ç–∞
                "auto_cleanup_failed": True,
                "cleanup_interval": 3600  # 1 —á–∞—Å
            }
        }
        
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                self.config = yaml.safe_load(f)
        else:
            self.config = default_config
            with open(config_path, 'w') as f:
                yaml.dump(self.config, f, default_flow_style=False)
    
    def init_server_discovery(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–æ–≤"""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        servers_config = self.config.get("known_servers", [])
        
        for server_config in servers_config:
            server = ServerInfo(
                host=server_config["host"],
                port=server_config.get("port", 22),
                username=server_config.get("username", "root"),
                ssh_key_path=server_config.get("ssh_key_path", "")
            )
            self.known_servers.append(server)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —Å–µ—Ä–≤–µ—Ä –∫–∞–∫ –±–∞–∑–æ–≤—ã–π
        local_server = ServerInfo(
            host="localhost",
            port=22,
            username=os.getenv("USER", "mentor"),
            status="available",
            cpu_cores=8,  # –ò–∑ –∞–Ω–∞–ª–∏–∑–∞ —Å–∏—Å—Ç–µ–º—ã
            memory_gb=12,
            disk_gb=100
        )
        self.known_servers.append(local_server)
    
    def start_background_processes(self):
        """–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤"""
        # –ü—Ä–æ—Ü–µ—Å—Å –ø–æ–∏—Å–∫–∞ –Ω–æ–≤—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
        discovery_thread = threading.Thread(
            target=self.run_server_discovery, 
            daemon=True
        )
        discovery_thread.start()
        
        # –ü—Ä–æ—Ü–µ—Å—Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã—Ö —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤
        monitoring_thread = threading.Thread(
            target=self.run_health_monitoring,
            daemon=True
        )
        monitoring_thread.start()
        
        # –ü—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–π
        cleanup_thread = threading.Thread(
            target=self.run_cleanup_process,
            daemon=True
        )
        cleanup_thread.start()
        
        logger.info("üîÑ –§–æ–Ω–æ–≤—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏ –∑–∞–ø—É—â–µ–Ω—ã")
    
    def run_server_discovery(self):
        """–ü–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤"""
        while True:
            try:
                if self.config.get("replication", {}).get("server_discovery", {}).get("enabled", False):
                    self.discover_new_servers()
                time.sleep(3600)  # –ö–∞–∂–¥—ã–π —á–∞—Å
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–æ–≤: {e}")
                time.sleep(300)
    
    def run_health_monitoring(self):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–¥–æ—Ä–æ–≤—å—è —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã—Ö —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤"""
        while True:
            try:
                self.check_deployed_instances_health()
                time.sleep(self.config["monitoring"]["health_check_interval"])
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}")
                time.sleep(60)
    
    def run_cleanup_process(self):
        """–û—á–∏—Å—Ç–∫–∞ –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–π"""
        while True:
            try:
                if self.config["monitoring"]["auto_cleanup_failed"]:
                    self.cleanup_failed_deployments()
                time.sleep(self.config["monitoring"]["cleanup_interval"])
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {e}")
                time.sleep(300)
    
    async def should_replicate(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥–∏ —Ä–µ—Å—É—Ä—Å–æ–≤
        cpu_threshold = self.config["replication"]["resource_thresholds"]["cpu_percent"]
        memory_threshold = self.config["replication"]["resource_thresholds"]["memory_percent"]
        tasks_threshold = self.config["replication"]["resource_thresholds"]["active_tasks"]
        
        current_cpu = self.core.state.resources_used.get("cpu", 0)
        current_memory = self.core.state.resources_used.get("memory", 0)
        current_tasks = self.core.state.active_tasks
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤
        max_instances = self.config["replication"]["max_instances"]
        current_instances = self.core.state.total_instances
        
        if current_instances >= max_instances:
            logger.info(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤: {max_instances}")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥–∏ —Ä–µ—Å—É—Ä—Å–æ–≤
        if (current_cpu > cpu_threshold or 
            current_memory > memory_threshold or 
            current_tasks > tasks_threshold):
            
            logger.info(f"üöÄ –¢—Ä–∏–≥–≥–µ—Ä —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏: CPU={current_cpu}%, Memory={current_memory}%, Tasks={current_tasks}")
            return True
        
        return False
    
    async def replicate(self) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏"""
        try:
            if not await self.should_replicate():
                return {"status": "not_needed", "reason": "–ü–æ—Ä–æ–≥–∏ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã"}
            
            logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å —Å–∞–º–æ–≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞...")
            
            # 1. –°–æ–∑–¥–∞–µ–º Docker –æ–±—Ä–∞–∑
            image = await self.create_deployment_image()
            if not image:
                return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å Docker –æ–±—Ä–∞–∑"}
            
            # 2. –ù–∞—Ö–æ–¥–∏–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä—ã
            available_servers = await self.find_available_servers()
            if not available_servers:
                return {"error": "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è"}
            
            # 3. –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π —Å–µ—Ä–≤–µ—Ä
            target_server = self.select_best_server(available_servers)
            if not target_server:
                return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Å–µ—Ä–≤–µ—Ä"}
            
            # 4. –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–µ–º –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ
            deployment_result = await self.deploy_to_server(target_server, image)
            
            # 5. –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
            if deployment_result.get("success"):
                self.core.state.total_instances += 1
                self.core.state.last_self_replication = datetime.now().isoformat()
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                self.replication_history.append({
                    "timestamp": datetime.now().isoformat(),
                    "target_server": target_server.server.host,
                    "success": True,
                    "deployment_time": deployment_result.get("deployment_time", 0)
                })
                
                logger.info(f"‚úÖ –†–µ–ø–ª–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä {target_server.server.host}")
            
            return deployment_result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏: {e}")
            return {"error": str(e)}
    
    async def create_deployment_image(self) -> Optional[docker.models.images.Image]:
        """–°–æ–∑–¥–∞–Ω–∏–µ Docker –æ–±—Ä–∞–∑–∞ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è"""
        try:
            logger.info("üì¶ –°–æ–∑–¥–∞–µ–º Docker –æ–±—Ä–∞–∑ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è...")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–±–æ—Ä–∫–∏
            build_dir = "/home/mentor/jarvis_data/deployment"
            Path(build_dir).mkdir(parents=True, exist_ok=True)
            
            # –°–æ–∑–¥–∞–µ–º Dockerfile
            dockerfile_content = f"""
FROM python:3.11-slim

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
RUN apt-get update && apt-get install -y \\
    docker.io \\
    openssh-client \\
    curl \\
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# –ö–æ–ø–∏—Ä—É–µ–º –∫–æ–¥ JARVIS
COPY jarvis_core.py .
COPY jarvis_integration.py .
COPY jarvis_replicator.py .

# –ö–æ–ø–∏—Ä—É–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# –ö–æ–ø–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
COPY config.yaml .
COPY replication_config.yaml .

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
RUN mkdir -p /app/jarvis_data/knowledge
RUN mkdir -p /app/jarvis_data/logs
RUN mkdir -p /app/jarvis_data/templates

# –ö–æ–ø–∏—Ä—É–µ–º —à–∞–±–ª–æ–Ω—ã
COPY templates/ ./templates/

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∞–≤–∞
RUN chmod +x jarvis_core.py

# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ—Ä—Ç
EXPOSE 8080

# –ö–æ–º–∞–Ω–¥–∞ –∑–∞–ø—É—Å–∫–∞
CMD ["python", "jarvis_core.py"]
"""
            
            with open(f"{build_dir}/Dockerfile", "w") as f:
                f.write(dockerfile_content)
            
            # –°–æ–∑–¥–∞–µ–º requirements.txt
            requirements_content = """
fastapi==0.104.1
uvicorn==0.24.0
docker==6.1.3
paramiko==3.3.1
pyyaml==6.0.1
requests==2.31.0
pandas==2.1.3
websockets==12.0
asyncio
"""
            
            with open(f"{build_dir}/requirements.txt", "w") as f:
                f.write(requirements_content)
            
            # –ö–æ–ø–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã
            import shutil
            files_to_copy = [
                "jarvis_core.py",
                "jarvis_integration.py", 
                "jarvis_replicator.py",
                "config.yaml",
                "replication_config.yaml"
            ]
            
            for file in files_to_copy:
                src = f"/home/mentor/jarvis_data/{file}"
                dst = f"{build_dir}/{file}"
                if os.path.exists(src):
                    shutil.copy2(src, dst)
            
            # –ö–æ–ø–∏—Ä—É–µ–º —à–∞–±–ª–æ–Ω—ã
            templates_src = "/home/mentor/jarvis_data/templates"
            templates_dst = f"{build_dir}/templates"
            if os.path.exists(templates_src):
                shutil.copytree(templates_src, templates_dst, dirs_exist_ok=True)
            
            # –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞–∑
            image, logs = self.docker_client.images.build(
                path=build_dir,
                tag=self.config["replication"]["deployment"]["image_tag"],
                rm=True
            )
            
            logger.info("‚úÖ Docker –æ–±—Ä–∞–∑ —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            return image
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Docker –æ–±—Ä–∞–∑–∞: {e}")
            return None
    
    async def find_available_servers(self) -> List[ReplicationTarget]:
        """–ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤"""
        available_targets = []
        
        for server in self.known_servers:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞
                if await self.check_server_availability(server):
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ—Å—É—Ä—Å–∞—Ö
                    resources = await self.get_server_resources(server)
                    
                    target = ReplicationTarget(
                        server=server,
                        priority=self.calculate_server_priority(server, resources),
                        resources_needed={
                            "cpu": 2,
                            "memory": 4, 
                            "disk": 20
                        }
                    )
                    
                    available_targets.append(target)
                    
            except Exception as e:
                logger.warning(f"–°–µ—Ä–≤–µ—Ä {server.host} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
                server.status = "offline"
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        available_targets.sort(key=lambda x: x.priority, reverse=True)
        
        return available_targets
    
    async def check_server_availability(self, server: ServerInfo) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º SSH –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            
            timeout = self.config["replication"]["server_discovery"]["ssh_timeout"]
            ssh.connect(
                hostname=server.host,
                port=server.port,
                username=server.username,
                key_filename=server.ssh_key_path if server.ssh_key_path else None,
                timeout=timeout
            )
            
            ssh.close()
            server.status = "available"
            server.last_check = datetime.now().isoformat()
            return True
            
        except Exception as e:
            server.status = "offline"
            server.last_check = datetime.now().isoformat()
            return False
    
    async def get_server_resources(self, server: ServerInfo) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–µ—Å—É—Ä—Å–∞—Ö —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect(
                hostname=server.host,
                port=server.port,
                username=server.username,
                key_filename=server.ssh_key_path if server.ssh_key_path else None,
                timeout=10
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ CPU
            stdin, stdout, stderr = ssh.exec_command("nproc")
            cpu_cores = int(stdout.read().decode().strip())
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–º—è—Ç–∏
            stdin, stdout, stderr = ssh.exec_command("free -m | awk 'NR==2{printf \"%.1f\", $2/1024}'")
            memory_gb = float(stdout.read().decode().strip())
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∏—Å–∫–µ
            stdin, stdout, stderr = ssh.exec_command("df -BG / | awk 'NR==2{print $4}' | sed 's/G//'")
            disk_gb = int(stdout.read().decode().strip())
            
            ssh.close()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ—Ä–≤–µ—Ä–µ
            server.cpu_cores = cpu_cores
            server.memory_gb = memory_gb
            server.disk_gb = disk_gb
            
            return {
                "cpu_cores": cpu_cores,
                "memory_gb": memory_gb,
                "disk_gb": disk_gb
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤ —Å–µ—Ä–≤–µ—Ä–∞ {server.host}: {e}")
            return {"cpu_cores": 0, "memory_gb": 0, "disk_gb": 0}
    
    def calculate_server_priority(self, server: ServerInfo, resources: Dict[str, Any]) -> int:
        """–†–∞—Å—á–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ —Å–µ—Ä–≤–µ—Ä–∞"""
        priority = 5  # –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
        if resources["cpu_cores"] >= 4:
            priority += 2
        if resources["memory_gb"] >= 8:
            priority += 2
        if resources["disk_gb"] >= 50:
            priority += 1
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å
        if server.status == "available":
            priority += 1
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø—Ä–æ–≤–µ—Ä–∫—É
        if server.last_check:
            last_check = datetime.fromisoformat(server.last_check)
            if (datetime.now() - last_check).seconds < 300:  # –ü—Ä–æ–≤–µ—Ä–µ–Ω –Ω–µ–¥–∞–≤–Ω–æ
                priority += 1
        
        return min(priority, 10)  # –ú–∞–∫—Å–∏–º—É–º 10
    
    def select_best_server(self, available_targets: List[ReplicationTarget]) -> Optional[ReplicationTarget]:
        """–í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è"""
        if not available_targets:
            return None
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å–µ—Ä–≤–µ—Ä —Å –Ω–∞–∏–≤—ã—Å—à–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
        best_target = available_targets[0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
        if (best_target.server.cpu_cores >= best_target.resources_needed["cpu"] and
            best_target.server.memory_gb >= best_target.resources_needed["memory"] and
            best_target.server.disk_gb >= best_target.resources_needed["disk"]):
            
            return best_target
        
        return None
    
    async def deploy_to_server(self, target: ReplicationTarget, image) -> Dict[str, Any]:
        """–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ"""
        start_time = time.time()
        
        try:
            logger.info(f"üöÄ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–µ–º JARVIS –Ω–∞ —Å–µ—Ä–≤–µ—Ä {target.server.host}...")
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect(
                hostname=target.server.host,
                port=target.server.port,
                username=target.server.username,
                key_filename=target.server.ssh_key_path if target.server.ssh_key_path else None,
                timeout=30
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Docker
            stdin, stdout, stderr = ssh.exec_command("docker --version")
            if stdout.channel.recv_exit_status() != 0:
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Docker
                logger.info("–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Docker –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ...")
                install_commands = [
                    "curl -fsSL https://get.docker.com -o get-docker.sh",
                    "sh get-docker.sh",
                    "systemctl start docker",
                    "systemctl enable docker"
                ]
                
                for cmd in install_commands:
                    stdin, stdout, stderr = ssh.exec_command(cmd)
                    stdout.channel.recv_exit_status()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–∑ –≤ —Ñ–∞–π–ª
            image_path = "/tmp/jarvis_image.tar"
            with open(image_path, "wb") as f:
                for chunk in image.save():
                    f.write(chunk)
            
            # –ö–æ–ø–∏—Ä—É–µ–º –æ–±—Ä–∞–∑ –Ω–∞ —Å–µ—Ä–≤–µ—Ä
            sftp = ssh.open_sftp()
            remote_image_path = "/tmp/jarvis_image.tar"
            sftp.put(image_path, remote_image_path)
            sftp.close()
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—Ä–∞–∑ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
            stdin, stdout, stderr = ssh.exec_command(f"docker load < {remote_image_path}")
            if stdout.channel.recv_exit_status() != 0:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å Docker –æ–±—Ä–∞–∑")
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–≤–æ–±–æ–¥–Ω—ã–π –ø–æ—Ä—Ç
            port = await self.find_free_port(target.server)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            container_name = f"{self.config['replication']['deployment']['container_name_prefix']}_{int(time.time())}"
            run_command = f"""
docker run -d \\
    --name {container_name} \\
    -p {port}:8080 \\
    --restart unless-stopped \\
    {self.config['replication']['deployment']['image_tag']}
"""
            
            stdin, stdout, stderr = ssh.exec_command(run_command)
            if stdout.channel.recv_exit_status() != 0:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–ø—É—Å—Ç–∏–ª—Å—è
            await asyncio.sleep(10)
            stdin, stdout, stderr = ssh.exec_command(f"docker ps | grep {container_name}")
            if stdout.channel.recv_exit_status() != 0:
                raise Exception("–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
            health_url = f"http://{target.server.host}:{port}/api/status"
            health_check = await self.check_health_endpoint(health_url)
            
            ssh.close()
            
            deployment_time = time.time() - start_time
            
            if health_check:
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∞–∫—Ç–∏–≤–Ω—ã–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è
                self.active_deployments[container_name] = {
                    "server": target.server.host,
                    "port": port,
                    "container_name": container_name,
                    "deployed_at": datetime.now().isoformat(),
                    "status": "running"
                }
                
                logger.info(f"‚úÖ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {deployment_time:.2f}—Å")
                
                return {
                    "success": True,
                    "server": target.server.host,
                    "port": port,
                    "container_name": container_name,
                    "deployment_time": deployment_time,
                    "health_check": True
                }
            else:
                raise Exception("Health check –Ω–µ –ø—Ä–æ—à–µ–ª")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ {target.server.host}: {e}")
            return {
                "success": False,
                "error": str(e),
                "server": target.server.host,
                "deployment_time": time.time() - start_time
            }
    
    async def find_free_port(self, server: ServerInfo) -> int:
        """–ü–æ–∏—Å–∫ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –ø–æ—Ä—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ"""
        port_range = self.config["replication"]["deployment"]["port_range"]
        
        for port in range(port_range[0], port_range[1]):
            try:
                ssh = paramiko.SSHClient()
                ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
                ssh.connect(
                    hostname=server.host,
                    port=server.port,
                    username=server.username,
                    key_filename=server.ssh_key_path if server.ssh_key_path else None,
                    timeout=10
                )
                
                stdin, stdout, stderr = ssh.exec_command(f"netstat -tln | grep :{port}")
                if stdout.channel.recv_exit_status() != 0:  # –ü–æ—Ä—Ç —Å–≤–æ–±–æ–¥–µ–Ω
                    ssh.close()
                    return port
                
                ssh.close()
            except:
                continue
        
        return port_range[0]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π –ø–æ—Ä—Ç –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
    
    async def check_health_endpoint(self, url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ health endpoint"""
        try:
            response = requests.get(url, timeout=30)
            return response.status_code == 200
        except:
            return False
    
    def discover_new_servers(self):
        """–ü–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤ –≤ —Å–µ—Ç–∏"""
        networks = self.config["replication"]["server_discovery"]["scan_networks"]
        ports = self.config["replication"]["server_discovery"]["common_ports"]
        
        for network in networks:
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ—Ç–∏
            # –ü–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞
            logger.info(f"–°–∫–∞–Ω–∏—Ä—É–µ–º —Å–µ—Ç—å {network}...")
    
    def check_deployed_instances_health(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã—Ö —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤"""
        for container_name, info in list(self.active_deployments.items()):
            try:
                health_url = f"http://{info['server']}:{info['port']}/api/status"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
                response = requests.get(health_url, timeout=10)
                if response.status_code != 200:
                    logger.warning(f"‚ö†Ô∏è –≠–∫–∑–µ–º–ø–ª—è—Ä {container_name} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                    info["status"] = "unhealthy"
                else:
                    info["status"] = "healthy"
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è {container_name}: {e}")
                info["status"] = "unhealthy"
    
    def cleanup_failed_deployments(self):
        """–û—á–∏—Å—Ç–∫–∞ –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–π"""
        for container_name, info in list(self.active_deployments.items()):
            if info["status"] == "unhealthy":
                logger.info(f"üßπ –£–¥–∞–ª—è–µ–º –Ω–µ—É–¥–∞—á–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ {container_name}")
                del self.active_deployments[container_name]
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤
                self.core.state.total_instances = max(1, self.core.state.total_instances - 1)
    
    def get_replication_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏"""
        return {
            "enabled": self.config["replication"]["enabled"],
            "total_instances": self.core.state.total_instances,
            "known_servers": len(self.known_servers),
            "active_deployments": len(self.active_deployments),
            "deployments": self.active_deployments,
            "replication_history": self.replication_history[-10:],  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10
            "last_replication": self.core.state.last_self_replication
        }



JARVIS Replicator Module
–°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –∏ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
"""

import os
import sys
import json
import time
import asyncio
import subprocess
import logging
import docker
import paramiko
import yaml
import requests
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import threading
import queue

logger = logging.getLogger(__name__)

@dataclass
class ServerInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–µ—Ä–≤–µ—Ä–µ"""
    host: str
    port: int = 22
    username: str = "root"
    ssh_key_path: str = ""
    cpu_cores: int = 0
    memory_gb: int = 0
    disk_gb: int = 0
    status: str = "unknown"  # available, busy, offline
    last_check: Optional[str] = None

@dataclass
class ReplicationTarget:
    """–¶–µ–ª—å –¥–ª—è —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏"""
    server: ServerInfo
    priority: int = 5  # 1-10
    resources_needed: Dict[str, float] = None
    deployment_time: Optional[str] = None
    
    def __post_init__(self):
        if self.resources_needed is None:
            self.resources_needed = {"cpu": 2, "memory": 4, "disk": 20}

class JarvisReplicator:
    """–°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ JARVIS"""
    
    def __init__(self, core):
        self.core = core
        self.docker_client = docker.from_env()
        self.known_servers = []
        self.replication_queue = queue.Queue()
        self.active_deployments = {}
        self.replication_history = []
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.load_config()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ —Å–µ—Ä–≤–µ—Ä–æ–≤
        self.init_server_discovery()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
        self.start_background_processes()
        
    def load_config(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏"""
        config_path = "/home/mentor/jarvis_data/replication_config.yaml"
        
        default_config = {
            "replication": {
                "enabled": True,
                "max_instances": 10,
                "resource_thresholds": {
                    "cpu_percent": 80,
                    "memory_percent": 85,
                    "active_tasks": 10
                },
                "deployment": {
                    "docker_registry": "localhost:5000",
                    "image_tag": "jarvis:latest",
                    "container_name_prefix": "jarvis_node",
                    "port_range": [8080, 8090]
                },
                "server_discovery": {
                    "enabled": True,
                    "scan_networks": ["192.168.1.0/24", "10.0.0.0/24"],
                    "common_ports": [22, 2222],
                    "ssh_timeout": 10
                }
            },
            "monitoring": {
                "health_check_interval": 300,  # 5 –º–∏–Ω—É—Ç
                "performance_check_interval": 60,  # 1 –º–∏–Ω—É—Ç–∞
                "auto_cleanup_failed": True,
                "cleanup_interval": 3600  # 1 —á–∞—Å
            }
        }
        
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                self.config = yaml.safe_load(f)
        else:
            self.config = default_config
            with open(config_path, 'w') as f:
                yaml.dump(self.config, f, default_flow_style=False)
    
    def init_server_discovery(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–æ–≤"""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        servers_config = self.config.get("known_servers", [])
        
        for server_config in servers_config:
            server = ServerInfo(
                host=server_config["host"],
                port=server_config.get("port", 22),
                username=server_config.get("username", "root"),
                ssh_key_path=server_config.get("ssh_key_path", "")
            )
            self.known_servers.append(server)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —Å–µ—Ä–≤–µ—Ä –∫–∞–∫ –±–∞–∑–æ–≤—ã–π
        local_server = ServerInfo(
            host="localhost",
            port=22,
            username=os.getenv("USER", "mentor"),
            status="available",
            cpu_cores=8,  # –ò–∑ –∞–Ω–∞–ª–∏–∑–∞ —Å–∏—Å—Ç–µ–º—ã
            memory_gb=12,
            disk_gb=100
        )
        self.known_servers.append(local_server)
    
    def start_background_processes(self):
        """–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤"""
        # –ü—Ä–æ—Ü–µ—Å—Å –ø–æ–∏—Å–∫–∞ –Ω–æ–≤—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
        discovery_thread = threading.Thread(
            target=self.run_server_discovery, 
            daemon=True
        )
        discovery_thread.start()
        
        # –ü—Ä–æ—Ü–µ—Å—Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã—Ö —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤
        monitoring_thread = threading.Thread(
            target=self.run_health_monitoring,
            daemon=True
        )
        monitoring_thread.start()
        
        # –ü—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–π
        cleanup_thread = threading.Thread(
            target=self.run_cleanup_process,
            daemon=True
        )
        cleanup_thread.start()
        
        logger.info("üîÑ –§–æ–Ω–æ–≤—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏ –∑–∞–ø—É—â–µ–Ω—ã")
    
    def run_server_discovery(self):
        """–ü–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤"""
        while True:
            try:
                if self.config.get("replication", {}).get("server_discovery", {}).get("enabled", False):
                    self.discover_new_servers()
                time.sleep(3600)  # –ö–∞–∂–¥—ã–π —á–∞—Å
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–æ–≤: {e}")
                time.sleep(300)
    
    def run_health_monitoring(self):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–¥–æ—Ä–æ–≤—å—è —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã—Ö —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤"""
        while True:
            try:
                self.check_deployed_instances_health()
                time.sleep(self.config["monitoring"]["health_check_interval"])
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}")
                time.sleep(60)
    
    def run_cleanup_process(self):
        """–û—á–∏—Å—Ç–∫–∞ –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–π"""
        while True:
            try:
                if self.config["monitoring"]["auto_cleanup_failed"]:
                    self.cleanup_failed_deployments()
                time.sleep(self.config["monitoring"]["cleanup_interval"])
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {e}")
                time.sleep(300)
    
    async def should_replicate(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥–∏ —Ä–µ—Å—É—Ä—Å–æ–≤
        cpu_threshold = self.config["replication"]["resource_thresholds"]["cpu_percent"]
        memory_threshold = self.config["replication"]["resource_thresholds"]["memory_percent"]
        tasks_threshold = self.config["replication"]["resource_thresholds"]["active_tasks"]
        
        current_cpu = self.core.state.resources_used.get("cpu", 0)
        current_memory = self.core.state.resources_used.get("memory", 0)
        current_tasks = self.core.state.active_tasks
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤
        max_instances = self.config["replication"]["max_instances"]
        current_instances = self.core.state.total_instances
        
        if current_instances >= max_instances:
            logger.info(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤: {max_instances}")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥–∏ —Ä–µ—Å—É—Ä—Å–æ–≤
        if (current_cpu > cpu_threshold or 
            current_memory > memory_threshold or 
            current_tasks > tasks_threshold):
            
            logger.info(f"üöÄ –¢—Ä–∏–≥–≥–µ—Ä —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏: CPU={current_cpu}%, Memory={current_memory}%, Tasks={current_tasks}")
            return True
        
        return False
    
    async def replicate(self) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏"""
        try:
            if not await self.should_replicate():
                return {"status": "not_needed", "reason": "–ü–æ—Ä–æ–≥–∏ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã"}
            
            logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å —Å–∞–º–æ–≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞...")
            
            # 1. –°–æ–∑–¥–∞–µ–º Docker –æ–±—Ä–∞–∑
            image = await self.create_deployment_image()
            if not image:
                return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å Docker –æ–±—Ä–∞–∑"}
            
            # 2. –ù–∞—Ö–æ–¥–∏–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä—ã
            available_servers = await self.find_available_servers()
            if not available_servers:
                return {"error": "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è"}
            
            # 3. –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π —Å–µ—Ä–≤–µ—Ä
            target_server = self.select_best_server(available_servers)
            if not target_server:
                return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Å–µ—Ä–≤–µ—Ä"}
            
            # 4. –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–µ–º –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ
            deployment_result = await self.deploy_to_server(target_server, image)
            
            # 5. –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
            if deployment_result.get("success"):
                self.core.state.total_instances += 1
                self.core.state.last_self_replication = datetime.now().isoformat()
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                self.replication_history.append({
                    "timestamp": datetime.now().isoformat(),
                    "target_server": target_server.server.host,
                    "success": True,
                    "deployment_time": deployment_result.get("deployment_time", 0)
                })
                
                logger.info(f"‚úÖ –†–µ–ø–ª–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä {target_server.server.host}")
            
            return deployment_result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏: {e}")
            return {"error": str(e)}
    
    async def create_deployment_image(self) -> Optional[docker.models.images.Image]:
        """–°–æ–∑–¥–∞–Ω–∏–µ Docker –æ–±—Ä–∞–∑–∞ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è"""
        try:
            logger.info("üì¶ –°–æ–∑–¥–∞–µ–º Docker –æ–±—Ä–∞–∑ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è...")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–±–æ—Ä–∫–∏
            build_dir = "/home/mentor/jarvis_data/deployment"
            Path(build_dir).mkdir(parents=True, exist_ok=True)
            
            # –°–æ–∑–¥–∞–µ–º Dockerfile
            dockerfile_content = f"""
FROM python:3.11-slim

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
RUN apt-get update && apt-get install -y \\
    docker.io \\
    openssh-client \\
    curl \\
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# –ö–æ–ø–∏—Ä—É–µ–º –∫–æ–¥ JARVIS
COPY jarvis_core.py .
COPY jarvis_integration.py .
COPY jarvis_replicator.py .

# –ö–æ–ø–∏—Ä—É–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# –ö–æ–ø–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
COPY config.yaml .
COPY replication_config.yaml .

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
RUN mkdir -p /app/jarvis_data/knowledge
RUN mkdir -p /app/jarvis_data/logs
RUN mkdir -p /app/jarvis_data/templates

# –ö–æ–ø–∏—Ä—É–µ–º —à–∞–±–ª–æ–Ω—ã
COPY templates/ ./templates/

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∞–≤–∞
RUN chmod +x jarvis_core.py

# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ—Ä—Ç
EXPOSE 8080

# –ö–æ–º–∞–Ω–¥–∞ –∑–∞–ø—É—Å–∫–∞
CMD ["python", "jarvis_core.py"]
"""
            
            with open(f"{build_dir}/Dockerfile", "w") as f:
                f.write(dockerfile_content)
            
            # –°–æ–∑–¥–∞–µ–º requirements.txt
            requirements_content = """
fastapi==0.104.1
uvicorn==0.24.0
docker==6.1.3
paramiko==3.3.1
pyyaml==6.0.1
requests==2.31.0
pandas==2.1.3
websockets==12.0
asyncio
"""
            
            with open(f"{build_dir}/requirements.txt", "w") as f:
                f.write(requirements_content)
            
            # –ö–æ–ø–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã
            import shutil
            files_to_copy = [
                "jarvis_core.py",
                "jarvis_integration.py", 
                "jarvis_replicator.py",
                "config.yaml",
                "replication_config.yaml"
            ]
            
            for file in files_to_copy:
                src = f"/home/mentor/jarvis_data/{file}"
                dst = f"{build_dir}/{file}"
                if os.path.exists(src):
                    shutil.copy2(src, dst)
            
            # –ö–æ–ø–∏—Ä—É–µ–º —à–∞–±–ª–æ–Ω—ã
            templates_src = "/home/mentor/jarvis_data/templates"
            templates_dst = f"{build_dir}/templates"
            if os.path.exists(templates_src):
                shutil.copytree(templates_src, templates_dst, dirs_exist_ok=True)
            
            # –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞–∑
            image, logs = self.docker_client.images.build(
                path=build_dir,
                tag=self.config["replication"]["deployment"]["image_tag"],
                rm=True
            )
            
            logger.info("‚úÖ Docker –æ–±—Ä–∞–∑ —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            return image
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Docker –æ–±—Ä–∞–∑–∞: {e}")
            return None
    
    async def find_available_servers(self) -> List[ReplicationTarget]:
        """–ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤"""
        available_targets = []
        
        for server in self.known_servers:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞
                if await self.check_server_availability(server):
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ—Å—É—Ä—Å–∞—Ö
                    resources = await self.get_server_resources(server)
                    
                    target = ReplicationTarget(
                        server=server,
                        priority=self.calculate_server_priority(server, resources),
                        resources_needed={
                            "cpu": 2,
                            "memory": 4, 
                            "disk": 20
                        }
                    )
                    
                    available_targets.append(target)
                    
            except Exception as e:
                logger.warning(f"–°–µ—Ä–≤–µ—Ä {server.host} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
                server.status = "offline"
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        available_targets.sort(key=lambda x: x.priority, reverse=True)
        
        return available_targets
    
    async def check_server_availability(self, server: ServerInfo) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º SSH –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            
            timeout = self.config["replication"]["server_discovery"]["ssh_timeout"]
            ssh.connect(
                hostname=server.host,
                port=server.port,
                username=server.username,
                key_filename=server.ssh_key_path if server.ssh_key_path else None,
                timeout=timeout
            )
            
            ssh.close()
            server.status = "available"
            server.last_check = datetime.now().isoformat()
            return True
            
        except Exception as e:
            server.status = "offline"
            server.last_check = datetime.now().isoformat()
            return False
    
    async def get_server_resources(self, server: ServerInfo) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–µ—Å—É—Ä—Å–∞—Ö —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect(
                hostname=server.host,
                port=server.port,
                username=server.username,
                key_filename=server.ssh_key_path if server.ssh_key_path else None,
                timeout=10
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ CPU
            stdin, stdout, stderr = ssh.exec_command("nproc")
            cpu_cores = int(stdout.read().decode().strip())
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–º—è—Ç–∏
            stdin, stdout, stderr = ssh.exec_command("free -m | awk 'NR==2{printf \"%.1f\", $2/1024}'")
            memory_gb = float(stdout.read().decode().strip())
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∏—Å–∫–µ
            stdin, stdout, stderr = ssh.exec_command("df -BG / | awk 'NR==2{print $4}' | sed 's/G//'")
            disk_gb = int(stdout.read().decode().strip())
            
            ssh.close()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ—Ä–≤–µ—Ä–µ
            server.cpu_cores = cpu_cores
            server.memory_gb = memory_gb
            server.disk_gb = disk_gb
            
            return {
                "cpu_cores": cpu_cores,
                "memory_gb": memory_gb,
                "disk_gb": disk_gb
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤ —Å–µ—Ä–≤–µ—Ä–∞ {server.host}: {e}")
            return {"cpu_cores": 0, "memory_gb": 0, "disk_gb": 0}
    
    def calculate_server_priority(self, server: ServerInfo, resources: Dict[str, Any]) -> int:
        """–†–∞—Å—á–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ —Å–µ—Ä–≤–µ—Ä–∞"""
        priority = 5  # –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
        if resources["cpu_cores"] >= 4:
            priority += 2
        if resources["memory_gb"] >= 8:
            priority += 2
        if resources["disk_gb"] >= 50:
            priority += 1
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å
        if server.status == "available":
            priority += 1
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø—Ä–æ–≤–µ—Ä–∫—É
        if server.last_check:
            last_check = datetime.fromisoformat(server.last_check)
            if (datetime.now() - last_check).seconds < 300:  # –ü—Ä–æ–≤–µ—Ä–µ–Ω –Ω–µ–¥–∞–≤–Ω–æ
                priority += 1
        
        return min(priority, 10)  # –ú–∞–∫—Å–∏–º—É–º 10
    
    def select_best_server(self, available_targets: List[ReplicationTarget]) -> Optional[ReplicationTarget]:
        """–í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è"""
        if not available_targets:
            return None
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å–µ—Ä–≤–µ—Ä —Å –Ω–∞–∏–≤—ã—Å—à–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
        best_target = available_targets[0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
        if (best_target.server.cpu_cores >= best_target.resources_needed["cpu"] and
            best_target.server.memory_gb >= best_target.resources_needed["memory"] and
            best_target.server.disk_gb >= best_target.resources_needed["disk"]):
            
            return best_target
        
        return None
    
    async def deploy_to_server(self, target: ReplicationTarget, image) -> Dict[str, Any]:
        """–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ"""
        start_time = time.time()
        
        try:
            logger.info(f"üöÄ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–µ–º JARVIS –Ω–∞ —Å–µ—Ä–≤–µ—Ä {target.server.host}...")
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect(
                hostname=target.server.host,
                port=target.server.port,
                username=target.server.username,
                key_filename=target.server.ssh_key_path if target.server.ssh_key_path else None,
                timeout=30
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Docker
            stdin, stdout, stderr = ssh.exec_command("docker --version")
            if stdout.channel.recv_exit_status() != 0:
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Docker
                logger.info("–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Docker –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ...")
                install_commands = [
                    "curl -fsSL https://get.docker.com -o get-docker.sh",
                    "sh get-docker.sh",
                    "systemctl start docker",
                    "systemctl enable docker"
                ]
                
                for cmd in install_commands:
                    stdin, stdout, stderr = ssh.exec_command(cmd)
                    stdout.channel.recv_exit_status()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–∑ –≤ —Ñ–∞–π–ª
            image_path = "/tmp/jarvis_image.tar"
            with open(image_path, "wb") as f:
                for chunk in image.save():
                    f.write(chunk)
            
            # –ö–æ–ø–∏—Ä—É–µ–º –æ–±—Ä–∞–∑ –Ω–∞ —Å–µ—Ä–≤–µ—Ä
            sftp = ssh.open_sftp()
            remote_image_path = "/tmp/jarvis_image.tar"
            sftp.put(image_path, remote_image_path)
            sftp.close()
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—Ä–∞–∑ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
            stdin, stdout, stderr = ssh.exec_command(f"docker load < {remote_image_path}")
            if stdout.channel.recv_exit_status() != 0:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å Docker –æ–±—Ä–∞–∑")
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–≤–æ–±–æ–¥–Ω—ã–π –ø–æ—Ä—Ç
            port = await self.find_free_port(target.server)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            container_name = f"{self.config['replication']['deployment']['container_name_prefix']}_{int(time.time())}"
            run_command = f"""
docker run -d \\
    --name {container_name} \\
    -p {port}:8080 \\
    --restart unless-stopped \\
    {self.config['replication']['deployment']['image_tag']}
"""
            
            stdin, stdout, stderr = ssh.exec_command(run_command)
            if stdout.channel.recv_exit_status() != 0:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–ø—É—Å—Ç–∏–ª—Å—è
            await asyncio.sleep(10)
            stdin, stdout, stderr = ssh.exec_command(f"docker ps | grep {container_name}")
            if stdout.channel.recv_exit_status() != 0:
                raise Exception("–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
            health_url = f"http://{target.server.host}:{port}/api/status"
            health_check = await self.check_health_endpoint(health_url)
            
            ssh.close()
            
            deployment_time = time.time() - start_time
            
            if health_check:
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∞–∫—Ç–∏–≤–Ω—ã–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è
                self.active_deployments[container_name] = {
                    "server": target.server.host,
                    "port": port,
                    "container_name": container_name,
                    "deployed_at": datetime.now().isoformat(),
                    "status": "running"
                }
                
                logger.info(f"‚úÖ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {deployment_time:.2f}—Å")
                
                return {
                    "success": True,
                    "server": target.server.host,
                    "port": port,
                    "container_name": container_name,
                    "deployment_time": deployment_time,
                    "health_check": True
                }
            else:
                raise Exception("Health check –Ω–µ –ø—Ä–æ—à–µ–ª")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ {target.server.host}: {e}")
            return {
                "success": False,
                "error": str(e),
                "server": target.server.host,
                "deployment_time": time.time() - start_time
            }
    
    async def find_free_port(self, server: ServerInfo) -> int:
        """–ü–æ–∏—Å–∫ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –ø–æ—Ä—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ"""
        port_range = self.config["replication"]["deployment"]["port_range"]
        
        for port in range(port_range[0], port_range[1]):
            try:
                ssh = paramiko.SSHClient()
                ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
                ssh.connect(
                    hostname=server.host,
                    port=server.port,
                    username=server.username,
                    key_filename=server.ssh_key_path if server.ssh_key_path else None,
                    timeout=10
                )
                
                stdin, stdout, stderr = ssh.exec_command(f"netstat -tln | grep :{port}")
                if stdout.channel.recv_exit_status() != 0:  # –ü–æ—Ä—Ç —Å–≤–æ–±–æ–¥–µ–Ω
                    ssh.close()
                    return port
                
                ssh.close()
            except:
                continue
        
        return port_range[0]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π –ø–æ—Ä—Ç –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
    
    async def check_health_endpoint(self, url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ health endpoint"""
        try:
            response = requests.get(url, timeout=30)
            return response.status_code == 200
        except:
            return False
    
    def discover_new_servers(self):
        """–ü–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤ –≤ —Å–µ—Ç–∏"""
        networks = self.config["replication"]["server_discovery"]["scan_networks"]
        ports = self.config["replication"]["server_discovery"]["common_ports"]
        
        for network in networks:
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ—Ç–∏
            # –ü–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞
            logger.info(f"–°–∫–∞–Ω–∏—Ä—É–µ–º —Å–µ—Ç—å {network}...")
    
    def check_deployed_instances_health(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã—Ö —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤"""
        for container_name, info in list(self.active_deployments.items()):
            try:
                health_url = f"http://{info['server']}:{info['port']}/api/status"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
                response = requests.get(health_url, timeout=10)
                if response.status_code != 200:
                    logger.warning(f"‚ö†Ô∏è –≠–∫–∑–µ–º–ø–ª—è—Ä {container_name} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                    info["status"] = "unhealthy"
                else:
                    info["status"] = "healthy"
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è {container_name}: {e}")
                info["status"] = "unhealthy"
    
    def cleanup_failed_deployments(self):
        """–û—á–∏—Å—Ç–∫–∞ –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–π"""
        for container_name, info in list(self.active_deployments.items()):
            if info["status"] == "unhealthy":
                logger.info(f"üßπ –£–¥–∞–ª—è–µ–º –Ω–µ—É–¥–∞—á–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ {container_name}")
                del self.active_deployments[container_name]
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤
                self.core.state.total_instances = max(1, self.core.state.total_instances - 1)
    
    def get_replication_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏"""
        return {
            "enabled": self.config["replication"]["enabled"],
            "total_instances": self.core.state.total_instances,
            "known_servers": len(self.known_servers),
            "active_deployments": len(self.active_deployments),
            "deployments": self.active_deployments,
            "replication_history": self.replication_history[-10:],  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10
            "last_replication": self.core.state.last_self_replication
        }