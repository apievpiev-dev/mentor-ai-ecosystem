#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—É—á–∞–µ—Ç, –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –∏ —É–ª—É—á—à–∞–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
"""

import asyncio
import json
import logging
import time
import uuid
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

from neural_network_creator_agent import neural_network_creator, NetworkArchitecture
from ai_engine import generate_ai_response

logger = logging.getLogger(__name__)

@dataclass
class TrainingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"""
    learning_rate: float
    batch_size: int
    epochs: int
    optimizer: str
    loss_function: str
    early_stopping_patience: int = 10
    learning_rate_decay: float = 0.95
    weight_decay: float = 1e-4
    dropout_rate: float = 0.2

@dataclass
class OptimizationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    best_config: TrainingConfig
    best_accuracy: float
    best_loss: float
    optimization_time: float
    iterations: int
    improvements: List[Dict[str, Any]]

class AutonomousNeuralNetworkTrainer:
    """–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π"""
    
    def __init__(self):
        self.training_queue = []
        self.active_training = {}
        self.optimization_history = []
        self.performance_metrics = {}
        self.auto_optimization_enabled = True
        self.continuous_learning = True
        self._setup_directories()
    
    def _setup_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        directories = [
            "/workspace/neural_networks/autonomous_training",
            "/workspace/neural_networks/optimization_results",
            "/workspace/neural_networks/performance_logs",
            "/workspace/neural_networks/auto_models"
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
    
    async def start_autonomous_training(self):
        """–ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π...")
        
        while self.continuous_learning:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—á–µ—Ä–µ–¥—å –æ–±—É—á–µ–Ω–∏—è
                if self.training_queue:
                    task = self.training_queue.pop(0)
                    await self._process_training_task(task)
                
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
                if self.auto_optimization_enabled:
                    await self._auto_optimize_networks()
                
                # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                await self._cleanup_old_data()
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏
                await asyncio.sleep(30)  # 30 —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏: {e}")
                await asyncio.sleep(60)  # –ü–∞—É–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    async def add_training_task(self, network_name: str, task_type: str = "train", 
                              config: TrainingConfig = None) -> str:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –≤ –æ—á–µ—Ä–µ–¥—å –æ–±—É—á–µ–Ω–∏—è"""
        task_id = str(uuid.uuid4())
        
        task = {
            "id": task_id,
            "network_name": network_name,
            "task_type": task_type,
            "config": config,
            "created_at": datetime.now().isoformat(),
            "status": "queued",
            "priority": 1
        }
        
        self.training_queue.append(task)
        logger.info(f"üìù –î–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞–¥–∞—á–∞ –æ–±—É—á–µ–Ω–∏—è: {task_id} –¥–ª—è —Å–µ—Ç–∏ {network_name}")
        
        return task_id
    
    async def _process_training_task(self, task: Dict[str, Any]):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ –æ–±—É—á–µ–Ω–∏—è"""
        try:
            task_id = task["id"]
            network_name = task["network_name"]
            task_type = task["task_type"]
            
            logger.info(f"üéØ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ {task_id}: {task_type} –¥–ª—è {network_name}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            task["status"] = "processing"
            self.active_training[task_id] = task
            
            if task_type == "train":
                await self._train_network_autonomous(network_name, task.get("config"))
            elif task_type == "optimize":
                await self._optimize_network_autonomous(network_name)
            elif task_type == "evaluate":
                await self._evaluate_network_autonomous(network_name)
            
            # –ó–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–¥–∞—á—É
            task["status"] = "completed"
            task["completed_at"] = datetime.now().isoformat()
            del self.active_training[task_id]
            
            logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏ {task_id}: {e}")
            task["status"] = "error"
            task["error"] = str(e)
            if task_id in self.active_training:
                del self.active_training[task_id]
    
    async def _train_network_autonomous(self, network_name: str, config: TrainingConfig = None):
        """–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ—Ç–∏
            networks_info = await neural_network_creator._handle_list_networks({})
            network_info = next((n for n in networks_info.get("networks", []) if n["name"] == network_name), None)
            
            if not network_info:
                raise Exception(f"–°–µ—Ç—å {network_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –æ–±—É—á–µ–Ω–∏—è
            if not config:
                config = await self._generate_optimal_config(network_info)
            
            # –û–±—É—á–∞–µ–º —Å–µ—Ç—å
            training_result = await neural_network_creator._handle_train_network({
                "network_name": network_name,
                "config": config.__dict__
            })
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            await self._save_training_results(network_name, training_result, config)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            await self._update_performance_metrics(network_name, training_result)
            
            logger.info(f"üéì –ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å–µ—Ç–∏ {network_name} –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è {network_name}: {e}")
            raise
    
    async def _optimize_network_autonomous(self, network_name: str):
        """–ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        try:
            logger.info(f"‚ö° –ù–∞—á–∏–Ω–∞—é –∞–≤—Ç–æ–Ω–æ–º–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —Å–µ—Ç–∏ {network_name}")
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            current_metrics = self.performance_metrics.get(network_name, {})
            baseline_accuracy = current_metrics.get("accuracy", 0.0)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            optimization_configs = await self._generate_optimization_configs(network_name)
            
            best_result = None
            best_accuracy = baseline_accuracy
            improvements = []
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
            for i, config in enumerate(optimization_configs):
                try:
                    logger.info(f"üß™ –¢–µ—Å—Ç–∏—Ä—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é {i+1}/{len(optimization_configs)}")
                    
                    # –û–±—É—á–∞–µ–º —Å –Ω–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
                    training_result = await neural_network_creator._handle_train_network({
                        "network_name": f"{network_name}_opt_{i}",
                        "config": config.__dict__
                    })
                    
                    if training_result.get("error"):
                        continue
                    
                    accuracy = training_result.get("final_accuracy", 0.0)
                    
                    improvement = {
                        "config": config.__dict__,
                        "accuracy": accuracy,
                        "improvement": accuracy - baseline_accuracy,
                        "timestamp": datetime.now().isoformat()
                    }
                    improvements.append(improvement)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ª—É—á—à–µ –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    if accuracy > best_accuracy:
                        best_accuracy = accuracy
                        best_result = {
                            "config": config,
                            "accuracy": accuracy,
                            "training_result": training_result
                        }
                    
                    logger.info(f"üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è {i+1}: —Ç–æ—á–Ω–æ—Å—Ç—å {accuracy:.2f}% (—É–ª—É—á—à–µ–Ω–∏–µ: {accuracy - baseline_accuracy:.2f}%)")
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {i+1}: {e}")
                    continue
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            if best_result:
                optimization_result = OptimizationResult(
                    best_config=best_result["config"],
                    best_accuracy=best_result["accuracy"],
                    best_loss=best_result["training_result"].get("final_loss", 0.0),
                    optimization_time=time.time(),
                    iterations=len(optimization_configs),
                    improvements=improvements
                )
                
                await self._save_optimization_results(network_name, optimization_result)
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª—É—á—à—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∫ –æ—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ç–∏
                await self._apply_best_config(network_name, best_result["config"])
                
                logger.info(f"üèÜ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {best_accuracy:.2f}%")
            else:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Ç–∏ {network_name}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ {network_name}: {e}")
            raise
    
    async def _generate_optimal_config(self, network_info: Dict[str, Any]) -> TrainingConfig:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            ai_prompt = f"""
            –°–æ–∑–¥–∞–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:
            –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {json.dumps(network_info.get('architecture', {}), indent=2)}
            –¢–µ–∫—É—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {network_info.get('test_accuracy', 0)}%
            
            –í–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏:
            - learning_rate: —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (0.001-0.1)
            - batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (16, 32, 64, 128)
            - epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö (10-100)
            - optimizer: –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (adam, sgd, rmsprop)
            - loss_function: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
            - early_stopping_patience: —Ç–µ—Ä–ø–µ–Ω–∏–µ early stopping (5-20)
            - learning_rate_decay: –∑–∞—Ç—É—Ö–∞–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è (0.9-0.99)
            - weight_decay: —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ (1e-5 –¥–æ 1e-3)
            - dropout_rate: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç dropout (0.1-0.5)
            """
            
            ai_response = await generate_ai_response(ai_prompt)
            
            try:
                config_data = json.loads(ai_response)
                return TrainingConfig(**config_data)
            except (json.JSONDecodeError, TypeError):
                # Fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
                return TrainingConfig(
                    learning_rate=0.001,
                    batch_size=32,
                    epochs=20,
                    optimizer="adam",
                    loss_function="cross_entropy",
                    early_stopping_patience=10,
                    learning_rate_decay=0.95,
                    weight_decay=1e-4,
                    dropout_rate=0.2
                )
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            return TrainingConfig(
                learning_rate=0.001,
                batch_size=32,
                epochs=20,
                optimizer="adam",
                loss_function="cross_entropy"
            )
    
    async def _generate_optimization_configs(self, network_name: str) -> List[TrainingConfig]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        configs = []
        
        # –ë–∞–∑–æ–≤—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        base_configs = [
            {"learning_rate": 0.001, "batch_size": 32, "optimizer": "adam"},
            {"learning_rate": 0.01, "batch_size": 64, "optimizer": "sgd"},
            {"learning_rate": 0.0001, "batch_size": 16, "optimizer": "rmsprop"},
            {"learning_rate": 0.005, "batch_size": 128, "optimizer": "adam"},
        ]
        
        for base in base_configs:
            config = TrainingConfig(
                learning_rate=base["learning_rate"],
                batch_size=base["batch_size"],
                epochs=15,
                optimizer=base["optimizer"],
                loss_function="cross_entropy",
                early_stopping_patience=8,
                learning_rate_decay=0.9,
                weight_decay=1e-4,
                dropout_rate=0.3
            )
            configs.append(config)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        try:
            ai_prompt = f"""
            –°–æ–∑–¥–∞–π 3 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ {network_name}.
            –ö–∞–∂–¥—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å JSON –æ–±—ä–µ–∫—Ç–æ–º —Å –ø–æ–ª—è–º–∏:
            - learning_rate, batch_size, epochs, optimizer, loss_function, early_stopping_patience, learning_rate_decay, weight_decay, dropout_rate
            
            –í–µ—Ä–Ω–∏ –º–∞—Å—Å–∏–≤ –∏–∑ 3 JSON –æ–±—ä–µ–∫—Ç–æ–≤.
            """
            
            ai_response = await generate_ai_response(ai_prompt)
            
            try:
                ai_configs = json.loads(ai_response)
                for config_data in ai_configs:
                    config = TrainingConfig(**config_data)
                    configs.append(config)
            except (json.JSONDecodeError, TypeError):
                logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ä—Å–∏—Ç—å AI –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ AI –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π: {e}")
        
        return configs
    
    async def _auto_optimize_networks(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö —Å–µ—Ç–µ–π"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–µ—Ç–µ–π
            networks_info = await neural_network_creator._handle_list_networks({})
            networks = networks_info.get("networks", [])
            
            for network in networks:
                network_name = network["name"]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–∞ –ª–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
                if await self._needs_optimization(network_name):
                    logger.info(f"üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–µ—Ç–∏ {network_name}")
                    await self.add_training_task(network_name, "optimize")
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
    
    async def _needs_optimization(self, network_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –Ω—É–∂–Ω–∞ –ª–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–µ—Ç–∏"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
            last_optimization = self.optimization_history[-1] if self.optimization_history else None
            
            if not last_optimization:
                return True
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            last_time = datetime.fromisoformat(last_optimization.get("timestamp", ""))
            if datetime.now() - last_time > timedelta(hours=1):  # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —á–∞—Å
                return True
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            current_metrics = self.performance_metrics.get(network_name, {})
            accuracy = current_metrics.get("accuracy", 0.0)
            
            if accuracy < 0.8:  # –ï—Å–ª–∏ —Ç–æ—á–Ω–æ—Å—Ç—å –º–µ–Ω—å—à–µ 80%
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
            return False
    
    async def _save_training_results(self, network_name: str, training_result: Dict[str, Any], 
                                   config: TrainingConfig):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        try:
            results = {
                "network_name": network_name,
                "config": config.__dict__,
                "training_result": training_result,
                "timestamp": datetime.now().isoformat()
            }
            
            results_path = f"/workspace/neural_networks/autonomous_training/{network_name}_training_{int(time.time())}.json"
            with open(results_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è: {e}")
    
    async def _save_optimization_results(self, network_name: str, result: OptimizationResult):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        try:
            optimization_data = {
                "network_name": network_name,
                "best_config": result.best_config.__dict__,
                "best_accuracy": result.best_accuracy,
                "best_loss": result.best_loss,
                "optimization_time": result.optimization_time,
                "iterations": result.iterations,
                "improvements": result.improvements,
                "timestamp": datetime.now().isoformat()
            }
            
            results_path = f"/workspace/neural_networks/optimization_results/{network_name}_optimization_{int(time.time())}.json"
            with open(results_path, 'w', encoding='utf-8') as f:
                json.dump(optimization_data, f, indent=2, ensure_ascii=False)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.optimization_history.append(optimization_data)
            
            logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
    
    async def _update_performance_metrics(self, network_name: str, training_result: Dict[str, Any]):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            if network_name not in self.performance_metrics:
                self.performance_metrics[network_name] = {}
            
            self.performance_metrics[network_name].update({
                "accuracy": training_result.get("final_accuracy", 0.0),
                "loss": training_result.get("final_loss", 0.0),
                "last_training": datetime.now().isoformat(),
                "training_history": training_result.get("training_history", [])
            })
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            metrics_path = f"/workspace/neural_networks/performance_logs/{network_name}_metrics.json"
            with open(metrics_path, 'w', encoding='utf-8') as f:
                json.dump(self.performance_metrics[network_name], f, indent=2, ensure_ascii=False)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}")
    
    async def _apply_best_config(self, network_name: str, config: TrainingConfig):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∫ —Å–µ—Ç–∏"""
        try:
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ª—É—á—à—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∫ –æ—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ç–∏
            # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
            logger.info(f"üéØ –ü—Ä–∏–º–µ–Ω—è—é –ª—É—á—à—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∫ —Å–µ—Ç–∏ {network_name}: {config.__dict__}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
    
    async def _cleanup_old_data(self):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (—Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π)
            cutoff_date = datetime.now() - timedelta(days=7)
            
            old_optimizations = [
                opt for opt in self.optimization_history
                if datetime.fromisoformat(opt.get("timestamp", "")) < cutoff_date
            ]
            
            for opt in old_optimizations:
                self.optimization_history.remove(opt)
            
            if old_optimizations:
                logger.info(f"üßπ –û—á–∏—â–µ–Ω–æ {len(old_optimizations)} —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    async def get_training_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
        return {
            "training_queue": len(self.training_queue),
            "active_training": len(self.active_training),
            "optimization_history": len(self.optimization_history),
            "performance_metrics": len(self.performance_metrics),
            "auto_optimization_enabled": self.auto_optimization_enabled,
            "continuous_learning": self.continuous_learning,
            "timestamp": datetime.now().isoformat()
        }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ —Ç—Ä–µ–Ω–µ—Ä–∞
autonomous_trainer = AutonomousNeuralNetworkTrainer()

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    try:
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ —Ç—Ä–µ–Ω–µ—Ä–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π...")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
        await autonomous_trainer.start_autonomous_training()
        
    except KeyboardInterrupt:
        logger.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ —Ç—Ä–µ–Ω–µ—Ä–∞...")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    asyncio.run(main())