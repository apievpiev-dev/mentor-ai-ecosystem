#!/usr/bin/env python3
"""
Enhanced AI Engine - –£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–≤–∏–∂–æ–∫ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –≤—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã, –≤–∏–∑—É–∞–ª—å–Ω—É—é –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é –∏ –∞–≤—Ç–æ–Ω–æ–º–Ω—É—é —Ä–∞–±–æ—Ç—É
"""

import asyncio
import json
import logging
import time
import base64
import io
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, asdict
from datetime import datetime
import aiohttp
import requests
from pathlib import Path
import subprocess
import os
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ ai_manager
sys.path.append('/workspace/ai_manager')

try:
    from ai_providers.provider_manager import AIProviderManager
    from ai_providers.ollama_provider import OllamaProvider
    from ai_providers.huggingface_provider import HuggingFaceProvider
    from ai_providers.local_provider import LocalProvider
except ImportError:
    print("‚ö†Ô∏è AI Manager –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é")

logger = logging.getLogger(__name__)

@dataclass
class AIResponse:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç AI –º–æ–¥–µ–ª–∏"""
    content: str
    model: str
    provider: str
    tokens_used: int = 0
    response_time: float = 0.0
    success: bool = True
    error: Optional[str] = None
    visual_verified: bool = False
    quality_score: float = 0.0
    metadata: Dict[str, Any] = None

@dataclass
class VisualVerification:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∏–∑—É–∞–ª—å–Ω–æ–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    verified: bool
    confidence: float
    issues: List[str]
    suggestions: List[str]
    screenshot_path: Optional[str] = None

class VisualIntelligence:
    """–°–∏—Å—Ç–µ–º–∞ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    
    def __init__(self):
        self.screenshots_dir = Path("/workspace/visual_screenshots")
        self.screenshots_dir.mkdir(exist_ok=True)
        self.verification_history = []
    
    async def verify_code_result(self, code: str, expected_output: str = None) -> VisualVerification:
        """–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–¥ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_file = Path("/tmp/test_code.py")
            temp_file.write_text(code)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–¥ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = subprocess.run([sys.executable, str(temp_file)], 
                                  capture_output=True, text=True, timeout=10)
            
            issues = []
            suggestions = []
            confidence = 1.0
            
            if result.returncode != 0:
                issues.append(f"–ö–æ–¥ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫–∏: {result.stderr}")
                confidence = 0.0
                suggestions.append("–ò—Å–ø—Ä–∞–≤–∏—Ç—å —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏")
            else:
                if expected_output and expected_output not in result.stdout:
                    issues.append("–†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–Ω–∏—è–º")
                    confidence = 0.5
                    suggestions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏–∫—É –∫–æ–¥–∞")
            
            # –°–æ–∑–¥–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç (–µ—Å–ª–∏ —ç—Ç–æ –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ)
            screenshot_path = None
            if "flask" in code.lower() or "fastapi" in code.lower() or "streamlit" in code.lower():
                screenshot_path = await self._capture_web_screenshot(code)
            
            return VisualVerification(
                verified=len(issues) == 0,
                confidence=confidence,
                issues=issues,
                suggestions=suggestions,
                screenshot_path=screenshot_path
            )
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            return VisualVerification(
                verified=False,
                confidence=0.0,
                issues=[f"–û—à–∏–±–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}"],
                suggestions=["–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–¥ –≤—Ä—É—á–Ω—É—é"]
            )
    
    async def _capture_web_screenshot(self, code: str) -> Optional[str]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Selenium
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            screenshot_path = self.screenshots_dir / f"web_app_{timestamp}.png"
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É —Å–∫—Ä–∏–Ω—à–æ—Ç–∞
            screenshot_path.write_bytes(b"")
            
            return str(screenshot_path)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞: {e}")
            return None
    
    async def verify_text_result(self, text: str, context: str = None) -> VisualVerification:
        """–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        issues = []
        suggestions = []
        confidence = 1.0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–∞
        if len(text.strip()) < 10:
            issues.append("–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π")
            confidence = 0.3
            suggestions.append("–†–∞—Å—à–∏—Ä–∏—Ç—å –æ—Ç–≤–µ—Ç")
        
        if not text.strip():
            issues.append("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            confidence = 0.0
            suggestions.append("–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫
        if "–æ—à–∏–±–∫–∞" in text.lower() or "error" in text.lower():
            issues.append("–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ")
            confidence = 0.5
            suggestions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞")
        
        return VisualVerification(
            verified=len(issues) == 0,
            confidence=confidence,
            issues=issues,
            suggestions=suggestions
        )

class EnhancedAIEngine:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π AI –¥–≤–∏–∂–æ–∫ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å–µ—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""
    
    def __init__(self):
        self.provider_manager = None
        self.visual_intelligence = VisualIntelligence()
        self.response_cache = {}
        self.performance_metrics = {
            "total_requests": 0,
            "successful_requests": 0,
            "average_response_time": 0.0,
            "cache_hits": 0
        }
        self.initialized = False
        
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–≤–∏–∂–∫–∞"""
        if self.initialized:
            return
        
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
            self.provider_manager = AIProviderManager()
            await self.provider_manager.initialize_providers({
                "ollama_model": "llama2:7b",
                "hf_model": "microsoft/DialoGPT-medium",
                "hf_token": os.getenv("HUGGINGFACE_TOKEN")
            })
            
            self.initialized = True
            logger.info("‚úÖ Enhanced AI Engine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Enhanced AI Engine: {e}")
            # –°–æ–∑–¥–∞–µ–º fallback –ø—Ä–æ–≤–∞–π–¥–µ—Ä
            self._create_fallback_providers()
    
    def _create_fallback_providers(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ fallback –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""
        try:
            from ai_providers.local_provider import LocalProvider
            self.provider_manager = AIProviderManager()
            self.provider_manager.providers["local"] = LocalProvider("fallback")
            self.provider_manager.default_provider = self.provider_manager.providers["local"]
            self.initialized = True
            logger.info("‚úÖ Fallback –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã —Å–æ–∑–¥–∞–Ω—ã")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è fallback –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤: {e}")
    
    async def generate_response(self, prompt: str, 
                              system_prompt: str = None,
                              provider: str = None,
                              enable_visual_verification: bool = True,
                              **kwargs) -> AIResponse:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –≤–∏–∑—É–∞–ª—å–Ω–æ–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–µ–π"""
        
        if not self.initialized:
            await self.initialize()
        
        start_time = time.time()
        self.performance_metrics["total_requests"] += 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cache_key = self._generate_cache_key(prompt, provider, kwargs)
        if cache_key in self.response_cache:
            self.performance_metrics["cache_hits"] += 1
            cached_response = self.response_cache[cache_key]
            cached_response.response_time = 0.01
            return cached_response
        
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ –ø—Ä–æ–≤–∞–π–¥–µ—Ä
            if self.provider_manager:
                result = await self.provider_manager.generate_response(
                    prompt, provider_name=provider, **kwargs
                )
            else:
                result = {"success": False, "error": "No providers available"}
            
            response_time = time.time() - start_time
            
            if result.get("success"):
                content = result.get("result", "")
                model = result.get("model", "unknown")
                provider_name = result.get("provider", "unknown")
                
                # –í–∏–∑—É–∞–ª—å–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
                visual_verification = None
                if enable_visual_verification:
                    if self._is_code_prompt(prompt):
                        visual_verification = await self.visual_intelligence.verify_code_result(content)
                    else:
                        visual_verification = await self.visual_intelligence.verify_text_result(content, prompt)
                
                # –°–æ–∑–¥–∞–µ–º –æ—Ç–≤–µ—Ç
                ai_response = AIResponse(
                    content=content,
                    model=model,
                    provider=provider_name,
                    response_time=response_time,
                    success=True,
                    visual_verified=visual_verification.verified if visual_verification else False,
                    quality_score=visual_verification.confidence if visual_verification else 1.0,
                    metadata={
                        "visual_verification": asdict(visual_verification) if visual_verification else None,
                        "cache_key": cache_key
                    }
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                self.response_cache[cache_key] = ai_response
                self.performance_metrics["successful_requests"] += 1
                
                return ai_response
            else:
                return AIResponse(
                    content="",
                    model="unknown",
                    provider="unknown",
                    response_time=response_time,
                    success=False,
                    error=result.get("error", "Unknown error")
                )
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return AIResponse(
                content="",
                model="unknown",
                provider="unknown",
                response_time=time.time() - start_time,
                success=False,
                error=str(e)
            )
    
    def _generate_cache_key(self, prompt: str, provider: str, kwargs: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫—ç—à–∞"""
        key_data = {
            "prompt": prompt[:100],
            "provider": provider,
            "temperature": kwargs.get("temperature", 0.7),
            "max_tokens": kwargs.get("max_tokens", 1000)
        }
        return base64.b64encode(json.dumps(key_data, sort_keys=True).encode()).decode()[:50]
    
    def _is_code_prompt(self, prompt: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø—Ä–æ–º–ø—Ç –∑–∞–ø—Ä–æ—Å–æ–º –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–¥–∞"""
        code_keywords = ["–∫–æ–¥", "code", "—Ñ—É–Ω–∫—Ü–∏—è", "function", "–∫–ª–∞—Å—Å", "class", 
                        "–ø—Ä–æ–≥—Ä–∞–º–º–∞", "program", "—Å–∫—Ä–∏–ø—Ç", "script", "–∞–ª–≥–æ—Ä–∏—Ç–º", "algorithm"]
        return any(keyword in prompt.lower() for keyword in code_keywords)
    
    async def get_available_models(self) -> Dict[str, List[str]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        if not self.initialized:
            await self.initialize()
        
        models = {}
        if self.provider_manager:
            for name, provider in self.provider_manager.providers.items():
                if hasattr(provider, 'get_supported_models'):
                    models[name] = provider.get_supported_models()
        
        return models
    
    async def get_system_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã"""
        if not self.initialized:
            await self.initialize()
        
        status = {
            "initialized": self.initialized,
            "providers": {},
            "performance": self.performance_metrics.copy(),
            "cache_size": len(self.response_cache)
        }
        
        if self.provider_manager:
            status["providers"] = await self.provider_manager.get_provider_health()
        
        return status
    
    async def optimize_performance(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –∫—ç—à–∞
        if len(self.response_cache) > 1000:
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 500 –∑–∞–ø–∏—Å–µ–π
            cache_items = list(self.response_cache.items())
            self.response_cache = dict(cache_items[-500:])
            logger.info("üßπ –ö—ç—à –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if self.performance_metrics["total_requests"] > 0:
            success_rate = self.performance_metrics["successful_requests"] / self.performance_metrics["total_requests"]
            cache_hit_rate = self.performance_metrics["cache_hits"] / self.performance_metrics["total_requests"]
            
            logger.info(f"üìä –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: —É—Å–ø–µ—à–Ω–æ—Å—Ç—å {success_rate:.2%}, –∫—ç—à {cache_hit_rate:.2%}")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –¥–≤–∏–∂–∫–∞
enhanced_ai_engine = EnhancedAIEngine()

# –£–¥–æ–±–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
async def generate_ai_response(prompt: str, system_prompt: str = None, **kwargs) -> str:
    """–ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"""
    response = await enhanced_ai_engine.generate_response(prompt, system_prompt, **kwargs)
    return response.content if response.success else f"–û—à–∏–±–∫–∞: {response.error}"

async def generate_code(prompt: str, language: str = "python") -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ —Å –≤–∏–∑—É–∞–ª—å–Ω–æ–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–µ–π"""
    system_prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç. –°–æ–∑–¥–∞–≤–∞–π –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π, —Ä–∞–±–æ—á–∏–π –∫–æ–¥ –Ω–∞ {language}.
    –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –∫–æ–¥–æ–º –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π, –µ—Å–ª–∏ –Ω–µ –ø—Ä–æ—Å—è—Ç –∏–Ω–∞—á–µ.
    –ö–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≥–æ—Ç–æ–≤ –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é."""
    
    response = await enhanced_ai_engine.generate_response(
        prompt, 
        system_prompt=system_prompt,
        enable_visual_verification=True
    )
    
    if response.success and response.visual_verified:
        return response.content
    elif response.success:
        logger.warning(f"‚ö†Ô∏è –ö–æ–¥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω, –Ω–æ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã: {response.metadata.get('visual_verification', {}).get('issues', [])}")
        return response.content
    else:
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞: {response.error}"

async def analyze_data(prompt: str) -> str:
    """–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
    system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ, –Ω–∞—Ö–æ–¥–∏ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏,
    —Å–æ–∑–¥–∞–≤–∞–π –∏–Ω—Å–∞–π—Ç—ã –∏ –¥–∞–≤–∞–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."""
    
    response = await enhanced_ai_engine.generate_response(prompt, system_prompt=system_prompt)
    return response.content if response.success else f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {response.error}"

async def plan_project(prompt: str) -> str:
    """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"""
    system_prompt = """–¢—ã –æ–ø—ã—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–µ–∫—Ç–æ–≤. –°–æ–∑–¥–∞–≤–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø–ª–∞–Ω—ã –ø—Ä–æ–µ–∫—Ç–æ–≤,
    —Ä–∞–∑–±–∏–≤–∞–π –∑–∞–¥–∞—á–∏ –Ω–∞ —ç—Ç–∞–ø—ã, –æ—Ü–µ–Ω–∏–≤–∞–π —Ä–∏—Å–∫–∏ –∏ —Ä–µ—Å—É—Ä—Å—ã."""
    
    response = await enhanced_ai_engine.generate_response(prompt, system_prompt=system_prompt)
    return response.content if response.success else f"–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {response.error}"

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ AI –¥–≤–∏–∂–∫–∞
    async def test_enhanced_ai():
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Enhanced AI Engine...")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        await enhanced_ai_engine.initialize()
        
        # –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
        status = await enhanced_ai_engine.get_system_status()
        print(f"–°—Ç–∞—Ç—É—Å: {status}")
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        test_prompts = [
            "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
            "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ —Å–ø–∏—Å–∫–∞ —á–∏—Å–µ–ª",
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ: [1, 2, 3, 4, 5]",
            "–°–æ–∑–¥–∞–π –ø–ª–∞–Ω —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"
        ]
        
        for prompt in test_prompts:
            print(f"\nüë§ –ó–∞–ø—Ä–æ—Å: {prompt}")
            response = await enhanced_ai_engine.generate_response(prompt)
            print(f"ü§ñ –û—Ç–≤–µ—Ç: {response.content[:100]}...")
            print(f"üìä –ö–∞—á–µ—Å—Ç–≤–æ: {response.quality_score:.2f}, –í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {response.visual_verified}")
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        await enhanced_ai_engine.optimize_performance()
    
    asyncio.run(test_enhanced_ai())