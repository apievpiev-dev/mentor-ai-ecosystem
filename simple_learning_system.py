#!/usr/bin/env python3
"""
Simple Learning System for JARVIS
–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è JARVIS –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
"""

import os
import sys
import json
import time
import threading
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from collections import defaultdict
import sqlite3

logger = logging.getLogger(__name__)

@dataclass
class LearningEvent:
    """–°–æ–±—ã—Ç–∏–µ –æ–±—É—á–µ–Ω–∏—è"""
    id: str
    timestamp: str
    event_type: str
    context: Dict[str, Any]
    outcome: Dict[str, Any]
    success: bool
    performance_impact: float

@dataclass
class Pattern:
    """–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω"""
    id: str
    pattern_type: str
    description: str
    conditions: Dict[str, Any]
    actions: List[str]
    confidence: float
    usage_count: int
    success_rate: float
    created_at: str

class SimpleLearningDatabase:
    """–ü—Ä–æ—Å—Ç–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, db_path: str = "/workspace/simple_learning.db"):
        self.db_path = db_path
        self.init_db()
    
    def init_db(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS events (
                    id TEXT PRIMARY KEY,
                    timestamp TEXT,
                    event_type TEXT,
                    context TEXT,
                    outcome TEXT,
                    success INTEGER,
                    performance_impact REAL
                )
            """)
            
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS patterns (
                    id TEXT PRIMARY KEY,
                    pattern_type TEXT,
                    description TEXT,
                    conditions TEXT,
                    actions TEXT,
                    confidence REAL,
                    usage_count INTEGER,
                    success_rate REAL,
                    created_at TEXT
                )
            """)
            
            conn.commit()
            conn.close()
            logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
    
    def save_event(self, event: LearningEvent):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR REPLACE INTO events 
                (id, timestamp, event_type, context, outcome, success, performance_impact)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                event.id, event.timestamp, event.event_type,
                json.dumps(event.context), json.dumps(event.outcome),
                1 if event.success else 0, event.performance_impact
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏—è: {e}")
    
    def get_recent_events(self, hours: int = 24) -> List[LearningEvent]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ–¥–∞–≤–Ω–∏—Ö —Å–æ–±—ã—Ç–∏–π"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            since_time = (datetime.now() - timedelta(hours=hours)).isoformat()
            
            cursor.execute("""
                SELECT * FROM events WHERE timestamp > ? ORDER BY timestamp DESC
            """, (since_time,))
            
            events = []
            for row in cursor.fetchall():
                event = LearningEvent(
                    id=row[0],
                    timestamp=row[1],
                    event_type=row[2],
                    context=json.loads(row[3]),
                    outcome=json.loads(row[4]),
                    success=bool(row[5]),
                    performance_impact=row[6]
                )
                events.append(event)
            
            conn.close()
            return events
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π: {e}")
            return []
    
    def save_pattern(self, pattern: Pattern):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR REPLACE INTO patterns 
                (id, pattern_type, description, conditions, actions, confidence, 
                 usage_count, success_rate, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                pattern.id, pattern.pattern_type, pattern.description,
                json.dumps(pattern.conditions), json.dumps(pattern.actions),
                pattern.confidence, pattern.usage_count, pattern.success_rate,
                pattern.created_at
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞: {e}")
    
    def get_patterns(self) -> List[Pattern]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("SELECT * FROM patterns ORDER BY confidence DESC")
            
            patterns = []
            for row in cursor.fetchall():
                pattern = Pattern(
                    id=row[0],
                    pattern_type=row[1],
                    description=row[2],
                    conditions=json.loads(row[3]),
                    actions=json.loads(row[4]),
                    confidence=row[5],
                    usage_count=row[6],
                    success_rate=row[7],
                    created_at=row[8]
                )
                patterns.append(pattern)
            
            conn.close()
            return patterns
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
            return []

class SimpleLearningSystem:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self):
        self.db = SimpleLearningDatabase()
        self.enabled = True
        self.patterns_cache = []
        self.learning_stats = {
            "events_processed": 0,
            "patterns_detected": 0,
            "adaptations_applied": 0,
            "success_rate": 0.0
        }
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ü–∏–∫–ª—ã –æ–±—É—á–µ–Ω–∏—è
        self.start_learning_cycles()
        
        logger.info("üß† Simple Learning System –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def start_learning_cycles(self):
        """–ó–∞–ø—É—Å–∫ —Ü–∏–∫–ª–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        def learning_loop():
            while self.enabled:
                try:
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏—è –∏ –∏—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                    self.analyze_and_learn()
                    time.sleep(120)  # –ö–∞–∂–¥—ã–µ 2 –º–∏–Ω—É—Ç—ã
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
                    time.sleep(300)
        
        threading.Thread(target=learning_loop, daemon=True).start()
        logger.info("üîÑ –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –∑–∞–ø—É—â–µ–Ω")
    
    def record_event(self, event_type: str, context: Dict[str, Any], 
                    outcome: Dict[str, Any], success: bool, performance_impact: float = 0.0):
        """–ó–∞–ø–∏—Å—å —Å–æ–±—ã—Ç–∏—è –æ–±—É—á–µ–Ω–∏—è"""
        try:
            event = LearningEvent(
                id=f"{event_type}_{int(time.time())}_{hash(str(context)) % 1000}",
                timestamp=datetime.now().isoformat(),
                event_type=event_type,
                context=context,
                outcome=outcome,
                success=success,
                performance_impact=performance_impact
            )
            
            self.db.save_event(event)
            self.learning_stats["events_processed"] += 1
            
            logger.info(f"üìö –°–æ–±—ã—Ç–∏–µ –∑–∞–ø–∏—Å–∞–Ω–æ: {event_type} (—É—Å–ø–µ—Ö: {success}, –≤–ª–∏—è–Ω–∏–µ: {performance_impact:+.2f})")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Å–æ–±—ã—Ç–∏—è: {e}")
    
    def analyze_and_learn(self):
        """–ê–Ω–∞–ª–∏–∑ —Å–æ–±—ã—Ç–∏–π –∏ –æ–±—É—á–µ–Ω–∏–µ"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–¥–∞–≤–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è
            events = self.db.get_recent_events(hours=6)
            
            if len(events) < 3:
                return
            
            logger.info(f"üîç –ê–Ω–∞–ª–∏–∑ {len(events)} —Å–æ–±—ã—Ç–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 6 —á–∞—Å–æ–≤")
            
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            patterns = self.detect_simple_patterns(events)
            
            if patterns:
                logger.info(f"üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(patterns)} –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
                
                for pattern in patterns:
                    self.db.save_pattern(pattern)
                    self.apply_pattern_learning(pattern)
                    self.learning_stats["patterns_detected"] += 1
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
            successful_events = [e for e in events if e.success]
            self.learning_stats["success_rate"] = len(successful_events) / len(events)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏ –æ–±—É—á–µ–Ω–∏—è: {e}")
    
    def detect_simple_patterns(self, events: List[LearningEvent]) -> List[Pattern]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        patterns = []
        
        try:
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏—è –ø–æ —Ç–∏–ø–∞–º
            event_groups = defaultdict(list)
            for event in events:
                event_groups[event.event_type].append(event)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É
            for event_type, type_events in event_groups.items():
                if len(type_events) >= 3:
                    pattern = self.analyze_event_group(event_type, type_events)
                    if pattern:
                        patterns.append(pattern)
            
            # –ò—â–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            temporal_pattern = self.detect_temporal_pattern(events)
            if temporal_pattern:
                patterns.append(temporal_pattern)
            
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            performance_pattern = self.detect_performance_pattern(events)
            if performance_pattern:
                patterns.append(performance_pattern)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
        
        return patterns
    
    def analyze_event_group(self, event_type: str, events: List[LearningEvent]) -> Optional[Pattern]:
        """–ê–Ω–∞–ª–∏–∑ –≥—Ä—É–ø–ø—ã —Å–æ–±—ã—Ç–∏–π –æ–¥–Ω–æ–≥–æ —Ç–∏–ø–∞"""
        try:
            success_rate = sum(1 for e in events if e.success) / len(events)
            avg_performance = sum(e.performance_impact for e in events) / len(events)
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —á–µ—Ç–∫–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω
            if success_rate > 0.8 and avg_performance > 0.05:
                # –£—Å–ø–µ—à–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
                pattern = Pattern(
                    id=f"success_{event_type}_{int(time.time())}",
                    pattern_type="success",
                    description=f"–í—ã—Å–æ–∫–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –¥–ª—è {event_type}: {success_rate:.1%}",
                    conditions={
                        "event_type": event_type,
                        "min_success_rate": 0.8,
                        "min_performance": 0.05
                    },
                    actions=[
                        f"–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á–∏ —Ç–∏–ø–∞ {event_type}",
                        "–ò–∑—É—á–∏—Ç—å —Ñ–∞–∫—Ç–æ—Ä—ã —É—Å–ø–µ—Ö–∞",
                        "–ü—Ä–∏–º–µ–Ω–∏—Ç—å –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –¥—Ä—É–≥–∏–º –∑–∞–¥–∞—á–∞–º"
                    ],
                    confidence=min(0.9, success_rate),
                    usage_count=0,
                    success_rate=success_rate,
                    created_at=datetime.now().isoformat()
                )
                return pattern
                
            elif success_rate < 0.5 or avg_performance < -0.1:
                # –ü—Ä–æ–±–ª–µ–º–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
                pattern = Pattern(
                    id=f"problem_{event_type}_{int(time.time())}",
                    pattern_type="problem",
                    description=f"–ù–∏–∑–∫–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –¥–ª—è {event_type}: {success_rate:.1%}",
                    conditions={
                        "event_type": event_type,
                        "max_success_rate": 0.5,
                        "max_performance": -0.1
                    },
                    actions=[
                        f"–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –ø—Ä–∏—á–∏–Ω—ã –Ω–µ—É–¥–∞—á –≤ {event_type}",
                        "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è",
                        "–î–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏"
                    ],
                    confidence=min(0.8, 1.0 - success_rate),
                    usage_count=0,
                    success_rate=success_rate,
                    created_at=datetime.now().isoformat()
                )
                return pattern
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≥—Ä—É–ø–ø—ã —Å–æ–±—ã—Ç–∏–π: {e}")
        
        return None
    
    def detect_temporal_pattern(self, events: List[LearningEvent]) -> Optional[Pattern]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        try:
            if len(events) < 5:
                return None
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —á–∞—Å–∞–º
            hourly_events = defaultdict(int)
            for event in events:
                hour = datetime.fromisoformat(event.timestamp).hour
                hourly_events[hour] += 1
            
            # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–æ–≤—ã–µ —á–∞—Å—ã
            max_events = max(hourly_events.values()) if hourly_events else 0
            avg_events = sum(hourly_events.values()) / len(hourly_events) if hourly_events else 0
            
            peak_hours = [hour for hour, count in hourly_events.items() if count > avg_events * 1.5]
            
            if peak_hours and max_events > avg_events * 1.5:
                pattern = Pattern(
                    id=f"temporal_{int(time.time())}",
                    pattern_type="temporal",
                    description=f"–ü–∏–∫–æ–≤–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ —á–∞—Å—ã: {peak_hours}",
                    conditions={
                        "peak_hours": peak_hours,
                        "peak_threshold": 1.5
                    },
                    actions=[
                        "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—Å—É—Ä—Å—ã –Ω–∞ –ø–∏–∫–æ–≤—ã–µ —á–∞—Å—ã",
                        "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –ø–∏–∫–æ–≤–æ–µ –≤—Ä–µ–º—è",
                        "–ò–∑–±–µ–≥–∞—Ç—å –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è –≤ –ø–∏–∫–æ–≤—ã–µ —á–∞—Å—ã"
                    ],
                    confidence=0.7,
                    usage_count=0,
                    success_rate=0.8,
                    created_at=datetime.now().isoformat()
                )
                return pattern
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞: {e}")
        
        return None
    
    def detect_performance_pattern(self, events: List[LearningEvent]) -> Optional[Pattern]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            performance_events = [e for e in events if abs(e.performance_impact) > 0.05]
            
            if len(performance_events) < 3:
                return None
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–¥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            positive_impact = [e for e in performance_events if e.performance_impact > 0]
            negative_impact = [e for e in performance_events if e.performance_impact < 0]
            
            if len(positive_impact) > len(negative_impact) * 2:
                # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥
                avg_improvement = sum(e.performance_impact for e in positive_impact) / len(positive_impact)
                
                pattern = Pattern(
                    id=f"performance_positive_{int(time.time())}",
                    pattern_type="performance_improvement",
                    description=f"–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: +{avg_improvement:.2f}",
                    conditions={
                        "positive_events": len(positive_impact),
                        "negative_events": len(negative_impact),
                        "avg_improvement": avg_improvement
                    },
                    actions=[
                        "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏",
                        "–ò–∑—É—á–∏—Ç—å —Ñ–∞–∫—Ç–æ—Ä—ã —É–ª—É—á—à–µ–Ω–∏—è",
                        "–ü—Ä–∏–º–µ–Ω–∏—Ç—å —É—Å–ø–µ—à–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∫ –¥—Ä—É–≥–∏–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º"
                    ],
                    confidence=0.8,
                    usage_count=0,
                    success_rate=0.9,
                    created_at=datetime.now().isoformat()
                )
                return pattern
                
            elif len(negative_impact) > len(positive_impact):
                # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–¥
                avg_degradation = sum(e.performance_impact for e in negative_impact) / len(negative_impact)
                
                pattern = Pattern(
                    id=f"performance_negative_{int(time.time())}",
                    pattern_type="performance_degradation",
                    description=f"–î–µ–≥—Ä–∞–¥–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {avg_degradation:.2f}",
                    conditions={
                        "negative_events": len(negative_impact),
                        "avg_degradation": avg_degradation
                    },
                    actions=[
                        "–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –ø—Ä–∏—á–∏–Ω—ã –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏",
                        "–û—Ç–∫–∞—Ç–∏—Ç—å –Ω–µ–¥–∞–≤–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è",
                        "–£—Å–∏–ª–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"
                    ],
                    confidence=0.7,
                    usage_count=0,
                    success_rate=0.6,
                    created_at=datetime.now().isoformat()
                )
                return pattern
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
        
        return None
    
    def apply_pattern_learning(self, pattern: Pattern):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        try:
            logger.info(f"üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è: {pattern.description}")
            
            # –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π
            for action in pattern.actions[:2]:  # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2 –¥–µ–π—Å—Ç–≤–∏—è
                logger.info(f"  üîß –î–µ–π—Å—Ç–≤–∏–µ: {action}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            pattern.usage_count += 1
            self.learning_stats["adaptations_applied"] += 1
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
            self.db.save_pattern(pattern)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è: {e}")
    
    def get_learning_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–¥–∞–≤–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è
            recent_events = self.db.get_recent_events(hours=24)
            patterns = self.db.get_patterns()
            
            return {
                "events_24h": len(recent_events),
                "success_rate_24h": sum(1 for e in recent_events if e.success) / len(recent_events) if recent_events else 0,
                "avg_performance_impact": sum(e.performance_impact for e in recent_events) / len(recent_events) if recent_events else 0,
                "total_patterns": len(patterns),
                "active_patterns": len([p for p in patterns if p.usage_count > 0]),
                "learning_enabled": self.enabled,
                "stats": self.learning_stats,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {"error": str(e)}

def test_simple_learning():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–π —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è"""
    try:
        logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Simple Learning System")
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É
        learning = SimpleLearningSystem()
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è
        test_events = [
            ("task_completion", {"task_type": "optimization", "agent": "optimizer"}, {"result": "success"}, True, 0.1),
            ("task_completion", {"task_type": "analysis", "agent": "analyzer"}, {"result": "success"}, True, 0.05),
            ("task_completion", {"task_type": "coordination", "agent": "coordinator"}, {"result": "partial"}, False, -0.02),
            ("visual_analysis", {"elements": 84, "issues": 0}, {"accessibility": 0.3}, True, 0.02),
            ("performance_check", {"cpu": 15.2, "memory": 12.1}, {"status": "good"}, True, 0.01),
            ("task_completion", {"task_type": "optimization", "agent": "optimizer"}, {"result": "success"}, True, 0.12),
            ("error_occurred", {"component": "analyzer", "error_type": "timeout"}, {"recovered": True}, False, -0.05)
        ]
        
        for event_type, context, outcome, success, impact in test_events:
            learning.record_event(event_type, context, outcome, success, impact)
            time.sleep(0.1)
        
        # –ñ–¥–µ–º –∞–Ω–∞–ª–∏–∑–∞
        logger.info("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤...")
        time.sleep(3)
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
        learning.analyze_and_learn()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = learning.get_learning_statistics()
        logger.info("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è:")
        logger.info(f"  –°–æ–±—ã—Ç–∏—è –∑–∞ 24—á: {stats.get('events_24h', 0)}")
        logger.info(f"  –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {stats.get('success_rate_24h', 0):.1%}")
        logger.info(f"  –í–ª–∏—è–Ω–∏–µ –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {stats.get('avg_performance_impact', 0):+.3f}")
        logger.info(f"  –í—Å–µ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {stats.get('total_patterns', 0)}")
        logger.info(f"  –ê–∫—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {stats.get('active_patterns', 0)}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        return False

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    test_simple_learning()